{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOSMn1ub21NYhKBj8nvRQE2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "47c201d64f6346da82f2648929290b5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1afda2e4eedd424d8ba52c7388adcd0a",
              "IPY_MODEL_9e313dd59c494c17b4215a28323f0483",
              "IPY_MODEL_096782446d8145ea81a7e41b60b67244"
            ],
            "layout": "IPY_MODEL_72b32e4a4d3d420f933da9b159288682"
          }
        },
        "1afda2e4eedd424d8ba52c7388adcd0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b06c612c40d495a895eb336e5136300",
            "placeholder": "​",
            "style": "IPY_MODEL_534e4865192e4f9cb86a3cf79c799535",
            "value": "100%"
          }
        },
        "9e313dd59c494c17b4215a28323f0483": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0bc3aef839fd4ab9ab446d8a0e2d14dc",
            "max": 5578,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9a2868387d9f41b5be37c5a2d50ebf47",
            "value": 5578
          }
        },
        "096782446d8145ea81a7e41b60b67244": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d7254b41dce045f5b95d26721f2b64fa",
            "placeholder": "​",
            "style": "IPY_MODEL_e609ba3ac5e140b19aa401546c2562e9",
            "value": " 5578/5578 [00:06&lt;00:00, 953.38 MB/s]"
          }
        },
        "72b32e4a4d3d420f933da9b159288682": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b06c612c40d495a895eb336e5136300": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "534e4865192e4f9cb86a3cf79c799535": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0bc3aef839fd4ab9ab446d8a0e2d14dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a2868387d9f41b5be37c5a2d50ebf47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d7254b41dce045f5b95d26721f2b64fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e609ba3ac5e140b19aa401546c2562e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3e8b14242c0d4f35b1fa40b553bea719": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ab72f5c0c492492eab624541d8d215d7",
              "IPY_MODEL_62fb248c6a4b41a8bda12e08c8987bdc",
              "IPY_MODEL_0840ef6af2094f619955780d6154738a"
            ],
            "layout": "IPY_MODEL_782153b3f1dd4a7c8aca5faaa80816c0"
          }
        },
        "ab72f5c0c492492eab624541d8d215d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_929f66cd9dcd4c6c83e80593055cbf71",
            "placeholder": "​",
            "style": "IPY_MODEL_fa338f02d37b4232a86f898ae7632ab9",
            "value": "100%"
          }
        },
        "62fb248c6a4b41a8bda12e08c8987bdc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f094100d09848a0ba43c3f635254a4d",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2ac506d8fde44e039d0a1c903b984015",
            "value": 1
          }
        },
        "0840ef6af2094f619955780d6154738a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03561f28d06d44e985e7c570f880f649",
            "placeholder": "​",
            "style": "IPY_MODEL_c4d19e3d6ad84555853dd017e9cdc921",
            "value": " 1/1 [00:00&lt;00:00, 98.66 MB/s]"
          }
        },
        "782153b3f1dd4a7c8aca5faaa80816c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "929f66cd9dcd4c6c83e80593055cbf71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa338f02d37b4232a86f898ae7632ab9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0f094100d09848a0ba43c3f635254a4d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ac506d8fde44e039d0a1c903b984015": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "03561f28d06d44e985e7c570f880f649": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4d19e3d6ad84555853dd017e9cdc921": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e86709845f3e4c0eae0d79b66cab4b31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d12847052f804506a0878c47ec1114bb",
              "IPY_MODEL_7bef755a3f5d4168a48cf42d70f46b3c",
              "IPY_MODEL_6161029ed68e4a9d8dae18e3d33c40c1"
            ],
            "layout": "IPY_MODEL_6bf3cde2478b44538535a8d144c82d9b"
          }
        },
        "d12847052f804506a0878c47ec1114bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ccac9c632884caca51da06a8849c47e",
            "placeholder": "​",
            "style": "IPY_MODEL_22324d41bb4a492dbc9a504c360c37b2",
            "value": "100%"
          }
        },
        "7bef755a3f5d4168a48cf42d70f46b3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0ff7a98e44c420986950c3c09f4f6a6",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1a0d2c37971d4095be7f3f899053725b",
            "value": 1
          }
        },
        "6161029ed68e4a9d8dae18e3d33c40c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e5faf3c508a4f7a8ad44842e5c3a3f3",
            "placeholder": "​",
            "style": "IPY_MODEL_ebe37b6899964869be8201f8f7d987d3",
            "value": " 1/1 [00:00&lt;00:00, 87.72 MB/s]"
          }
        },
        "6bf3cde2478b44538535a8d144c82d9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ccac9c632884caca51da06a8849c47e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22324d41bb4a492dbc9a504c360c37b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a0ff7a98e44c420986950c3c09f4f6a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a0d2c37971d4095be7f3f899053725b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7e5faf3c508a4f7a8ad44842e5c3a3f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ebe37b6899964869be8201f8f7d987d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MacKumachin/Clifford-FBSM-SignalControl/blob/main/GCTAD_SOTA_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "L2aSMeD-F9Eh",
        "outputId": "2173d939-5d86-45f9-ddc1-28c3aa5e40f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "[CGTAD] /content/B_streamlines.trk\n",
            "[seeds] 197959  [estimated step] 0.500 mm\n",
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "❌ DWI.nii(.gz) / bvals / bvecs が見つかりません。Driveの場所を教えるか、DICOMをzipでアップロードしてください。",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m ❌ DWI.nii(.gz) / bvals / bvecs が見つかりません。Driveの場所を教えるか、DICOMをzipでアップロードしてください。\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py:3561: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ]
        }
      ],
      "source": [
        "# === リセット一発セル：u=0 Baseline 生成 → CGTADと比較（Colab） ===\n",
        "# 1) 依存とツール\n",
        "#!pip -q install -U numpy scipy nibabel dipy statsmodels pandas scikit-image\n",
        "!apt-get -qq update && apt-get -qq install -y dcm2niix >/dev/null\n",
        "\n",
        "import os, re, glob, json, numpy as np, matplotlib.pyplot as plt\n",
        "from nibabel.streamlines import load as sl_load\n",
        "from dipy.io.image import load_nifti\n",
        "from dipy.core.gradients import gradient_table\n",
        "from dipy.segment.mask import median_otsu\n",
        "from dipy.reconst.csdeconv import auto_response_ssst, ConstrainedSphericalDeconvModel\n",
        "from dipy.direction import peaks_from_model\n",
        "from dipy.data import default_sphere\n",
        "from dipy.tracking.stopping_criterion import BinaryStoppingCriterion\n",
        "from dipy.tracking.local_tracking import LocalTracking\n",
        "from dipy.tracking.streamline import Streamlines\n",
        "from dipy.io.streamline import save_trk\n",
        "\n",
        "# 2) 設定（ここだけ編集）：あなたの CGTAD .trk の実パス\n",
        "CGTAD_TRK = \"/content/drive/MyDrive/CGTAD/B_streamlines.trk\"  # ←必要に応じて修正\n",
        "\n",
        "# 3) CGTAD が見つからなければ自動探索\n",
        "if not os.path.exists(CGTAD_TRK):\n",
        "    cands = glob.glob(\"/content/**/*.trk\", recursive=True)\n",
        "    cands = [p for p in cands if re.search(r\"(B_stream|cgtad|opt)\", os.path.basename(p), re.I)]\n",
        "    if not cands:\n",
        "        raise SystemExit(\"❌ CGTAD .trk が見つかりません。CGTAD_TRK を実パスに直してください。\")\n",
        "    CGTAD_TRK = sorted(cands)[0]\n",
        "print(\"[CGTAD]\", CGTAD_TRK)\n",
        "\n",
        "# 4) CGTAD の種点（最初の頂点）を seeds に採用、ステップ長も推定\n",
        "obj = sl_load(CGTAD_TRK)\n",
        "streams = [np.asarray(s, dtype=np.float64) for s in obj.streamlines if len(s)>=2]\n",
        "seeds_world = [s[0] for s in streams]\n",
        "# ステップ長の中央値（mm）\n",
        "def step_median_mm(s):\n",
        "    d = np.diff(s, axis=0);\n",
        "    return float(np.median(np.linalg.norm(d, axis=1))) if d.size else np.nan\n",
        "STEP_MM = float(np.nanmedian([step_median_mm(s) for s in streams]))\n",
        "if not np.isfinite(STEP_MM): STEP_MM = 0.5\n",
        "print(f\"[seeds] {len(seeds_world)}  [estimated step] {STEP_MM:.3f} mm\")\n",
        "\n",
        "# 5) DWI の取得：既存NIfTIを探す → 無ければ Drive から DICOM候補→自動変換\n",
        "DWI_PATH=BVAL_PATH=BVECS_PATH=None\n",
        "# 5-1) 既存のNIfTI三点セットを /content と Drive から検索\n",
        "roots = [\"/content\", \"/content/drive/MyDrive\", \"/content/drive/Shareddrives\"]\n",
        "def find_files(patterns):\n",
        "    out=[]\n",
        "    for r in roots:\n",
        "        for pat in patterns:\n",
        "            out += glob.glob(os.path.join(r, \"**\", pat), recursive=True)\n",
        "    return sorted(set(out))\n",
        "nii  = find_files([\"*dwi*.nii*\", \"*data.nii*\"])\n",
        "bval = find_files([\"*.bval\", \"*bval*\"])\n",
        "bvec = find_files([\"*.bvec\", \"*bvec*\"])\n",
        "if nii and bval and bvec:\n",
        "    DWI_PATH, BVAL_PATH, BVECS_PATH = nii[0], bval[0], bvec[0]\n",
        "\n",
        "# 5-2) 無ければ Drive をマウントして DICOM を変換\n",
        "if not (DWI_PATH and BVAL_PATH and BVECS_PATH):\n",
        "    try:\n",
        "        from google.colab import drive\n",
        "        if not os.path.ismount(\"/content/drive\"):\n",
        "            drive.mount(\"/content/drive\")\n",
        "    except Exception:\n",
        "        pass\n",
        "    # DICOM候補（枚数が多いフォルダ）\n",
        "    cands=[]\n",
        "    for root in roots[1:]:\n",
        "        for dp, dn, fn in os.walk(root):\n",
        "            n=0\n",
        "            for f in fn:\n",
        "                fl=f.lower()\n",
        "                if fl.endswith((\".dcm\",\".ima\",\".dicom\")) or bool(re.fullmatch(r\"\\d{5,}\", f)):\n",
        "                    n+=1\n",
        "            if n>=30: cands.append((n,dp))\n",
        "    cands.sort(reverse=True)\n",
        "    if cands:\n",
        "        DICOM_DIR=cands[0][1]\n",
        "        print(\"[DICOM candidate]\", DICOM_DIR, f\"(files≈{cands[0][0]})\")\n",
        "        os.makedirs(\"/content/dwi_out\", exist_ok=True)\n",
        "        # 変換\n",
        "        get_ipython().system('dcm2niix -ba y -z y -o /content/dwi_out -f dwi \"{DICOM_DIR}\"')\n",
        "        nii  = sorted(glob.glob(\"/content/dwi_out/*.nii*\"))\n",
        "        bval = sorted(glob.glob(\"/content/dwi_out/*.bval\"))\n",
        "        bvec = sorted(glob.glob(\"/content/dwi_out/*.bvec\"))\n",
        "        if nii and bval and bvec:\n",
        "            DWI_PATH, BVAL_PATH, BVECS_PATH = nii[0], bval[0], bvec[0]\n",
        "\n",
        "if not (DWI_PATH and BVAL_PATH and BVECS_PATH):\n",
        "    raise SystemExit(\"❌ DWI.nii(.gz) / bvals / bvecs が見つかりません。Driveの場所を教えるか、DICOMをzipでアップロードしてください。\")\n",
        "\n",
        "print(\"DWI :\", DWI_PATH)\n",
        "print(\"bvals:\", BVAL_PATH)\n",
        "print(\"bvecs:\", BVECS_PATH)\n",
        "\n",
        "# 6) DIPYで u=0 Baseline 生成（制御なし・同じ種点・推定ステップ長）\n",
        "data, affine = load_nifti(DWI_PATH)\n",
        "bvals = np.loadtxt(BVAL_PATH); bvecs = np.loadtxt(BVECS_PATH)\n",
        "gtab = gradient_table(bvals, bvecs)\n",
        "masked, brainmask = median_otsu(data, numpass=2)\n",
        "response, ratio   = auto_response_ssst(gtab, masked, roi_radius=10, fa_thr=0.7)\n",
        "csd = ConstrainedSphericalDeconvModel(gtab, response, sh_order=8)\n",
        "peaks = peaks_from_model(csd, masked, default_sphere,\n",
        "                         relative_peak_threshold=0.8, min_separation_angle=25,\n",
        "                         mask=brainmask, npeaks=5, normalize_peaks=True)\n",
        "stop = BinaryStoppingCriterion(peaks.gfa > 0.2)\n",
        "\n",
        "streamlines_u0 = Streamlines(LocalTracking(\n",
        "    peaks, stop, seeds_world, affine, step_size=float(STEP_MM), max_cross=1, return_all=False\n",
        "))\n",
        "\n",
        "os.makedirs(\"/content/baseline_eval\", exist_ok=True)\n",
        "BASE_TRK = \"/content/baseline_eval/baseline_u0_sameSeeds.trk\"\n",
        "save_trk(streamlines_u0, BASE_TRK, affine=affine, shape=data.shape[:3])\n",
        "print(f\"[saved baseline] {BASE_TRK}  n={len(streamlines_u0)}\")\n",
        "\n",
        "# 7) 指標（長さ/平均曲率）を読み出し、CGTAD と重ねヒスト → PDF と LaTeXマクロ\n",
        "def load_len_curv(trk):\n",
        "    obj = sl_load(trk); Ls, Ks = [], []\n",
        "    for s in obj.streamlines:\n",
        "        s = np.asarray(s, dtype=np.float64)\n",
        "        if s.shape[0] >= 2:\n",
        "            d = np.diff(s, axis=0); Ls.append(float(np.sum(np.linalg.norm(d, axis=1))))\n",
        "        if s.shape[0] >= 3:\n",
        "            p0,p1,p2=s[:-2],s[1:-1],s[2:]; v1=p1-p0; v2=p2-p1\n",
        "            L1=np.linalg.norm(v1,axis=1)+1e-9; L2=np.linalg.norm(v2,axis=1)+1e-9\n",
        "            ct=np.clip(np.sum(v1*v2,axis=1)/(L1*L2),-1,1); th=np.arccos(ct); smean=0.5*(L1+L2)+1e-9\n",
        "            k=2.0*np.sin(0.5*th)/smean\n",
        "            if k.size: Ks.append(float(np.mean(k)))\n",
        "    return np.asarray(Ls), np.asarray(Ks)\n",
        "\n",
        "Lb,Kb = load_len_curv(BASE_TRK)\n",
        "Lc,Kc = load_len_curv(CGTAD_TRK)\n",
        "\n",
        "def plot_overlay(a,b,title,xlabel,out,bins=64):\n",
        "    lo = min(float(np.min(a)) if a.size else 0, float(np.min(b)) if b.size else 0)\n",
        "    hi = max(float(np.max(a)) if a.size else 1, float(np.max(b)) if b.size else 1)\n",
        "    if not np.isfinite(lo) or not np.isfinite(hi) or lo==hi: lo,hi=0.0,max(1.0,hi if np.isfinite(hi) else 1.0)\n",
        "    edges = np.linspace(lo, hi, bins+1)\n",
        "    plt.figure(figsize=(6,5))\n",
        "    plt.hist(a, bins=edges, alpha=0.5, label=\"Baseline (u=0)\")\n",
        "    plt.hist(b, bins=edges, alpha=0.5, label=\"CGTAD\")\n",
        "    plt.title(title); plt.xlabel(xlabel); plt.ylabel(\"count\"); plt.legend()\n",
        "    os.makedirs(os.path.dirname(out), exist_ok=True)\n",
        "    plt.tight_layout(); plt.savefig(out, bbox_inches=\"tight\"); plt.close()\n",
        "\n",
        "os.makedirs(\"/content/compare_eval\", exist_ok=True)\n",
        "plot_overlay(Lb,Lc,\"Length distribution (u=0 vs CGTAD)\",\"Length (mm)\",\"/content/compare_eval/overlay_Length_mm.pdf\")\n",
        "plot_overlay(Kb,Kc,\"Curvature distribution (u=0 vs CGTAD)\",\"Curvature (1/mm)\",\"/content/compare_eval/overlay_Curvature_1_mm.pdf\")\n",
        "print(\"[saved] /content/compare_eval/overlay_Length_mm.pdf\")\n",
        "print(\"[saved] /content/compare_eval/overlay_Curvature_1_mm.pdf\")\n",
        "\n",
        "def fmt(v,p=3):\n",
        "    if not np.isfinite(v): return '---'\n",
        "    if v!=0 and (abs(v)<1e-4 or abs(v)>=1e4): return f\"{v:.{p}e}\"\n",
        "    return f\"{v:.{p}f}\"\n",
        "def dpp(a,b):\n",
        "    if not (np.isfinite(a) and np.isfinite(b)) or a==0: return '---'\n",
        "    return f\"{100.0*(b-a)/abs(a):.1f}\"\n",
        "def summarize(arr):\n",
        "    return dict(mean=float(np.mean(arr)) if arr.size else float(\"nan\"),\n",
        "                std=float(np.std(arr)) if arr.size else float(\"nan\"),\n",
        "                n=int(arr.size))\n",
        "\n",
        "summs = {\"length_mm\":{\"base\":summarize(Lb),\"cgtad\":summarize(Lc)},\n",
        "         \"curv_1_per_mm\":{\"base\":summarize(Kb),\"cgtad\":summarize(Kc)}}\n",
        "\n",
        "os.makedirs(\"tex\", exist_ok=True)\n",
        "lines = [\n",
        "  \"% Auto-generated: Baseline(u=0 same seeds) vs CGTAD\",\n",
        "  r\"\\providecommand{\\CompLenBase}{%s}\"     % fmt(summs[\"length_mm\"][\"base\"][\"mean\"],2),\n",
        "  r\"\\providecommand{\\CompLenCtl}{%s}\"      % fmt(summs[\"length_mm\"][\"cgtad\"][\"mean\"],2),\n",
        "  r\"\\providecommand{\\CompLenDeltaPct}{%s}\" % dpp(summs[\"length_mm\"][\"base\"][\"mean\"], summs[\"length_mm\"][\"cgtad\"][\"mean\"]),\n",
        "  r\"\\providecommand{\\CompCurvBase}{%s}\"    % fmt(summs[\"curv_1_per_mm\"][\"base\"][\"mean\"],3),\n",
        "  r\"\\providecommand{\\CompCurvCtl}{%s}\"     % fmt(summs[\"curv_1_per_mm\"][\"cgtad\"][\"mean\"],3),\n",
        "  r\"\\providecommand{\\CompCurvDeltaPct}{%s}\"% dpp(summs[\"curv_1_per_mm\"][\"base\"][\"mean\"], summs[\"curv_1_per_mm\"][\"cgtad\"][\"mean\"]),\n",
        "]\n",
        "open(\"tex/compare_macros_generated.tex\",\"w\",encoding=\"utf-8\").write(\"\\n\".join(lines)+\"\\n\")\n",
        "print(\"[macros] tex/compare_macros_generated.tex\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive; import os, glob\n",
        "if not os.path.ismount('/content/drive'):\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "roots = ['/content','/content/drive/MyDrive','/content/drive/Shareddrives']\n",
        "def scan(patterns):\n",
        "    out=[]\n",
        "    for r in roots:\n",
        "        for p in patterns:\n",
        "            out += glob.glob(os.path.join(r,'**',p), recursive=True)\n",
        "    return sorted(set(out))\n",
        "\n",
        "nii  = scan(['*dwi*.nii*','*data.nii*'])\n",
        "bval = scan(['*.bval','*bval*'])\n",
        "bvec = scan(['*.bvec','*bvec*'])\n",
        "print('NIfTI:', nii[:10]); print('bvals:', bval[:10]); print('bvecs:', bvec[:10])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z86NKsbPNczM",
        "outputId": "45c39b1e-2e80-4e2d-d100-4449dd11a0c6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NIfTI: []\n",
            "bvals: []\n",
            "bvecs: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === 強化サーチ：NIfTI と bvals/bvecs を広めに探す ===\n",
        "from google.colab import drive; import os, glob\n",
        "if not os.path.ismount('/content/drive'): drive.mount('/content/drive')\n",
        "\n",
        "roots = ['/content','/content/drive/MyDrive','/content/drive/Shareddrives']\n",
        "nii_pats  = ['*dwi*.nii*','*diff*.nii*','*DTI*.nii*','*data*.nii*','*nii.gz']\n",
        "bval_pats = ['*.bval','*bval*','*bvals*']\n",
        "bvec_pats = ['*.bvec','*bvec*','*bvecs*']\n",
        "\n",
        "def find(patterns):\n",
        "    hits=set()\n",
        "    for r in roots:\n",
        "        for p in patterns:\n",
        "            hits.update(glob.glob(os.path.join(r,'**',p), recursive=True))\n",
        "    return sorted(hits)\n",
        "\n",
        "def show(hits, tag):\n",
        "    from pathlib import Path\n",
        "    print(f\"\\n[{tag}] {len(hits)} files\")\n",
        "    for p in hits[:20]:  # 20件まで\n",
        "        try:\n",
        "            sz = os.path.getsize(p)/1e6\n",
        "            print(f\"{sz:6.1f} MB  {p}\")\n",
        "        except: print(p)\n",
        "\n",
        "nii  = find(nii_pats);  show(nii,'NIfTI candidates')\n",
        "bval = find(bval_pats); show(bval,'bvals candidates')\n",
        "bvec = find(bvec_pats); show(bvec,'bvecs candidates')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wrsumjP5Oohi",
        "outputId": "dbf2440f-39a4-4d3d-9f45-db9e135af593"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[NIfTI candidates] 0 files\n",
            "\n",
            "[bvals candidates] 0 files\n",
            "\n",
            "[bvecs candidates] 0 files\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nibabel.streamlines import load\n",
        "import numpy as np, os, glob, json\n",
        "\n",
        "p = \"/content/drive/MyDrive/CGTAD/B_streamlines.trk\"  # 置いた場所に合わせて\n",
        "obj = load(p)\n",
        "hdr = obj.header\n",
        "\n",
        "print(\"voxsize:\", tuple(float(x) for x in hdr[\"voxel_sizes\"]))\n",
        "print(\"dim    :\", tuple(int(x) for x in hdr[\"dim\"]))\n",
        "print(\"n_streamlines:\", len(obj.streamlines))\n",
        "\n",
        "# 代表的な推定：1.25mmならHCP、~2.0mmなら(Stanford) HARDI 系の可能性大\n",
        "vs = float(hdr[\"voxel_sizes\"][0])\n",
        "if 1.20 <= vs <= 1.30:\n",
        "    print(\"→ たぶん HCP 解像度\")\n",
        "elif 1.9 <= vs <= 2.1:\n",
        "    print(\"→ たぶん HARDI(2mm) 系\")\n",
        "else:\n",
        "    print(\"→ 別解像度（プロトコルを確認）\")\n",
        "\n",
        "# だれが生成したかの手掛かり（保存元セル探索）\n",
        "!grep -R --line-number -e \"B_streamlines.trk\" -e \"save_trk\" /content || true\n",
        "!find /content -type f -name \"B_streamlines.trk\" -printf \"%TY-%Tm-%Td %TH:%TM  %p\\n\" | sort\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "abM9g8GNUEqs",
        "outputId": "cc1b5fda-dd1f-48e2-ea0e-40478ba96158"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "voxsize: (2.0, 2.0, 2.0)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'dim'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1810477890.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"voxsize:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhdr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"voxel_sizes\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dim    :\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhdr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"dim\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"n_streamlines:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstreamlines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'dim'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nibabel.streamlines import load\n",
        "p = \"/content/drive/MyDrive/CGTAD/B_streamlines.trk\"  # パスは合わせて\n",
        "\n",
        "obj = load(p)\n",
        "hdr = obj.header\n",
        "\n",
        "# まずキー一覧を確認\n",
        "print(\"keys:\", sorted(hdr.keys()))\n",
        "\n",
        "# 安全に取得\n",
        "voxsize = tuple(float(x) for x in hdr.get('voxel_sizes', hdr.get('voxel_size', [])))\n",
        "dims    = tuple(int(x)   for x in hdr.get('dimensions',  hdr.get('dim', [])))\n",
        "n_strm  = len(obj.streamlines)\n",
        "\n",
        "print(\"voxel_sizes:\", voxsize)\n",
        "print(\"dimensions :\", dims)\n",
        "print(\"n_streamlines:\", n_strm)\n",
        "\n",
        "# ざっくり判定\n",
        "if voxsize and 1.20 <= voxsize[0] <= 1.30:\n",
        "    print(\"→ HCP 解像度の可能性が高い\")\n",
        "elif voxsize and 1.9 <= voxsize[0] <= 2.1:\n",
        "    print(\"→ HARDI(2mm) 系の可能性が高い\")\n",
        "else:\n",
        "    print(\"→ いずれでもない解像度（元データを要確認）\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-JHShuOxg-uW",
        "outputId": "aee23b8f-829d-4a7c-81e7-d43ece46b16e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "keys: ['_offset_data', 'dimensions', 'endianness', 'hdr_size', 'image_orientation_patient', 'invert_x', 'invert_y', 'invert_z', 'magic_number', 'nb_properties_per_streamline', 'nb_scalars_per_point', 'nb_streamlines', 'origin', 'pad1', 'pad2', 'property_name', 'reserved', 'scalar_name', 'swap_xy', 'swap_yz', 'swap_zx', 'version', 'voxel_order', 'voxel_sizes', 'voxel_to_rasmm']\n",
            "voxel_sizes: (2.0, 2.0, 2.0)\n",
            "dimensions : (81, 106, 76)\n",
            "n_streamlines: 204419\n",
            "→ HARDI(2mm) 系の可能性が高い\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from nibabel.streamlines import load as trk_load\n",
        "\n",
        "def _len_mm(s):\n",
        "    if s.shape[0] < 2: return 0.0\n",
        "    d = np.diff(s, axis=0)\n",
        "    return float(np.linalg.norm(d, axis=1).sum())\n",
        "\n",
        "def _curv_mean(s, eps=1e-9):\n",
        "    if s.shape[0] < 3: return np.nan\n",
        "    p0,p1,p2 = s[:-2], s[1:-1], s[2:]\n",
        "    v1 = p1 - p0; v2 = p2 - p1\n",
        "    L1 = np.linalg.norm(v1, axis=1) + eps\n",
        "    L2 = np.linalg.norm(v2, axis=1) + eps\n",
        "    ct = np.clip(np.sum(v1*v2, axis=1) / (L1*L2), -1, 1)\n",
        "    th = np.arccos(ct); smean = 0.5*(L1+L2) + eps\n",
        "    k = 2.0*np.sin(0.5*th)/smean  # 1/mm\n",
        "    return float(np.nanmean(k)) if k.size else np.nan\n",
        "\n",
        "def extract_arrays(trk_path):\n",
        "    \"\"\"trk から (長さmm配列, 曲率1/mm配列) を返す\"\"\"\n",
        "    obj = trk_load(trk_path)\n",
        "    Ls, Ks = [], []\n",
        "    for s in obj.streamlines:\n",
        "        s = np.asarray(s, dtype=np.float64)\n",
        "        if s.shape[0] >= 2:\n",
        "            Ls.append(_len_mm(s))\n",
        "        if s.shape[0] >= 3:\n",
        "            kv = _curv_mean(s)\n",
        "            if np.isfinite(kv): Ks.append(kv)\n",
        "    return np.array(Ls, dtype=float), np.array(Ks, dtype=float)\n"
      ],
      "metadata": {
        "id": "V-E7L112vvvl"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# こういう誤記を探します\n",
        "import re, inspect\n",
        "print(re.findall(r\"np\\.array\\(\\s*\\[,\\s*float\", open('/content/*.py','r').read() ))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        },
        "id": "vWpO7CDuv33R",
        "outputId": "76a4e2d0-26af-4e43-9aa7-2316637d4529"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/*.py'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3551039950.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# こういう誤記を探します\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\"np\\.array\\(\\s*\\[,\\s*float\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/*.py'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/*.py'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Stanford HARDI を用いた u=0 ベースライン生成（同じ seeds）+ 比較図・TeX 一発セル ===\n",
        "# 依存\n",
        "import sys, os, json, numpy as np, matplotlib.pyplot as plt\n",
        "from nibabel.streamlines import load as trk_load\n",
        "import nibabel as nib\n",
        "\n",
        "# DIPY が使えない場合だけ最小限インストール（numpyは現状維持）\n",
        "try:\n",
        "    import dipy\n",
        "except Exception:\n",
        "    !pip -q install dipy nibabel scikit-image scipy\n",
        "\n",
        "from dipy.data import fetch_stanford_hardi, read_stanford_hardi\n",
        "from dipy.segment.mask import median_otsu\n",
        "from dipy.reconst.csdeconv import ConstrainedSphericalDeconvModel, auto_response_ssst\n",
        "from dipy.direction import peaks_from_model\n",
        "from dipy.tracking.local_tracking import LocalTracking\n",
        "from dipy.tracking.streamline import Streamlines\n",
        "from dipy.tracking.stopping_criterion import BinaryStoppingCriterion\n",
        "from dipy.io.streamline import save_trk\n",
        "\n",
        "# ---------- ユーザ環境の CGTAD .trk ----------\n",
        "CGTAD_TRK = \"/content/drive/MyDrive/CGTAD/B_streamlines.trk\"  # 必要なら変更\n",
        "\n",
        "# ---------- .trk 読み込み＆step推定＆seed抽出 ----------\n",
        "obj = trk_load(CGTAD_TRK)\n",
        "hdr = obj.header\n",
        "streams = [np.asarray(s, dtype=np.float64) for s in obj.streamlines]\n",
        "n_str = len(streams)\n",
        "voxsize = tuple(float(x) for x in hdr.get('voxel_sizes', hdr.get('voxel_size', [])))\n",
        "print(f\"[CGTAD] {CGTAD_TRK}\")\n",
        "print(f\"        n={n_str}, vox={voxsize}\")\n",
        "\n",
        "# 推定 step（平均セグメント長）\n",
        "def est_step(ss):\n",
        "    lens=[]\n",
        "    for s in ss:\n",
        "        if s.shape[0] < 2: continue\n",
        "        d = np.diff(s, axis=0)\n",
        "        lens += list(np.linalg.norm(d, axis=1))\n",
        "    if not lens: return 0.5\n",
        "    m = float(np.median(lens))\n",
        "    return max(0.25, min(1.5, round(m, 3)))\n",
        "\n",
        "STEP_MM = est_step(streams)\n",
        "print(f\"[seeds] estimated step ~ {STEP_MM} mm\")\n",
        "\n",
        "# seeds（各ストリームの開始点, world(mm)）\n",
        "seeds_world = np.array([s[0] for s in streams if len(s)>=1], dtype=np.float64)\n",
        "print(f\"[seeds] count = {seeds_world.shape[0]}\")\n",
        "\n",
        "# ---------- Stanford HARDI を取得 ----------\n",
        "fetch_stanford_hardi()\n",
        "data, affine, gtab = read_stanford_hardi()\n",
        "print(\"[HARDI] data shape:\", data.shape, \"vox:\", tuple(np.sqrt((affine[:3,:3]**2).sum(0))))\n",
        "\n",
        "# seeds の妥当性チェック（画像内に入っているか）\n",
        "ijk = nib.affines.apply_affine(np.linalg.inv(affine), seeds_world)\n",
        "inside = (\n",
        "    (ijk[:,0] >= 0) & (ijk[:,0] < data.shape[0]) &\n",
        "    (ijk[:,1] >= 0) & (ijk[:,1] < data.shape[1]) &\n",
        "    (ijk[:,2] >= 0) & (ijk[:,2] < data.shape[2])\n",
        ")\n",
        "valid_seeds = seeds_world[inside]\n",
        "drop = seeds_world.shape[0] - valid_seeds.shape[0]\n",
        "print(f\"[seeds] valid {valid_seeds.shape[0]} / dropped {drop}\")\n",
        "\n",
        "# 妥当な seeds が少なすぎる場合は mask ベースにフォールバック\n",
        "if valid_seeds.shape[0] < 1000:\n",
        "    print(\"[warn] seeds が画像外に多いのでフォールバック（脳マスクから均一seeding）\")\n",
        "    data_masked, mask = median_otsu(data, vol_idx=range(data.shape[3]), numpass=2)\n",
        "    # 粗密は必要に応じ調整\n",
        "    se = np.argwhere(mask)[::4]  # 4ボクセルに1点\n",
        "    # voxel→world\n",
        "    valid_seeds = nib.affines.apply_affine(affine, se)\n",
        "\n",
        "# ---------- CSD モデル & 方向場 ----------\n",
        "data_masked, mask = median_otsu(data, vol_idx=range(data.shape[3]), numpass=2)\n",
        "response, ratio = auto_response_ssst(gtab, data_masked, roi_radius=10, fa_thr=0.7)\n",
        "csd_model = ConstrainedSphericalDeconvModel(gtab, response)\n",
        "peaks = peaks_from_model(csd_model, data_masked, sphere=None,\n",
        "                         relative_peak_threshold=0.5,\n",
        "                         min_separation_angle=25, mask=mask,\n",
        "                         return_sh=False, normalize_peaks=True)\n",
        "stop = BinaryStoppingCriterion(mask)\n",
        "\n",
        "# ---------- LocalTracking（u=0 ベースライン） ----------\n",
        "stream_gen = LocalTracking(peaks, stop, valid_seeds, affine,\n",
        "                           step_size=float(STEP_MM), max_cross=1,\n",
        "                           return_all=False)\n",
        "baseline = Streamlines(stream_gen)\n",
        "\n",
        "# 保存\n",
        "os.makedirs(\"/content/baseline_eval\", exist_ok=True)\n",
        "BASE_TRK = \"/content/baseline_eval/baseline_u0_sameSeeds.trk\"\n",
        "save_trk(BASE_TRK, baseline, affine=affine)\n",
        "print(f\"[saved baseline] {BASE_TRK}  (n={len(baseline)})\")\n",
        "\n",
        "# ---------- 評価：長さ & 曲率 ----------\n",
        "def len_mm(s):\n",
        "    if s.shape[0] < 2: return 0.0\n",
        "    d = np.diff(s,axis=0)\n",
        "    return float(np.sum(np.linalg.norm(d,axis=1)))\n",
        "def curv_mean(s, eps=1e-9):\n",
        "    if s.shape[0] < 3: return np.nan\n",
        "    p0,p1,p2 = s[:-2], s[1:-1], s[2:]\n",
        "    v1 = p1-p0; v2 = p2-p1\n",
        "    L1 = np.linalg.norm(v1,axis=1)+eps; L2 = np.linalg.norm(v2,axis=1)+eps\n",
        "    ct = np.clip(np.sum(v1*v2,axis=1)/(L1*L2), -1, 1)\n",
        "    th = np.arccos(ct); smean = 0.5*(L1+L2)+eps\n",
        "    k = 2.0*np.sin(0.5*th)/smean  # 1/mm\n",
        "    return float(np.nanmean(k)) if k.size else np.nan\n",
        "\n",
        "def extract_arrays(trk_path):\n",
        "    obj = trk_load(trk_path)\n",
        "    L=[]; K=[]\n",
        "    for s in obj.streamlines:\n",
        "        s=np.asarray(s, dtype=np.float64)\n",
        "        if s.shape[0] < 2: continue\n",
        "        L.append(len_mm(s))\n",
        "        if s.shape[0] >= 3:\n",
        "            kv = curv_mean(s)\n",
        "            if np.isfinite(kv): K.append(kv)\n",
        "    return np.array(L, np.array(K, float)\n",
        "\n",
        "Lb, Kb = extract_arrays(BASE_TRK)\n",
        "Lc, Kc = extract_arrays(CGTAD_TRK)\n",
        "\n",
        "print(\"[auto] baseline:\", len(Lb), \"   CGTAD:\", len(Lc))\n",
        "\n",
        "# ---------- 図（重ねヒスト） ----------\n",
        "def plot_overlay(a,b, title, xl, out, bins=64):\n",
        "    plt.figure(figsize=(6.4,5))\n",
        "    lo = float(np.nanmin(np.r_[a,b])) if a.size and b.size else 0.0\n",
        "    hi = float(np.nanmax(np.r_[a,b])) if a.size and b.size else 1.0\n",
        "    lo, hi = max(lo,0.0), max(hi,1e-6)\n",
        "    edges = np.linspace(lo, hi, bins+1)\n",
        "    plt.hist(a, bins=edges, alpha=0.6, label=\"Baseline (u=0)\")\n",
        "    plt.hist(b, bins=edges, alpha=0.6, label=\"CGTAD\")\n",
        "    plt.title(title); float), plt.xlabel(xl); plt.ylabel(\"count\"); plt.legend()\n",
        "    os.makedirs(os.path.dirname(out), exist_ok=True)\n",
        "    plt.tight_layout(); plt.savefig(out, bbox_inches=\"tight\"); plt.close()\n",
        "\n",
        "plot_overlay(Lb,Lc, \"Length distribution (Baseline vs CGTAD)\", \"Length (mm)\",\n",
        "             \"/content/compare_eval/overlay_Length_mm.pdf\")\n",
        "plot_overlay(Kb,Kc, \"Curvature distribution (Baseline vs CGTAD)\", \"Curvature (1/mm)\",\n",
        "             \"/content/compare_eval/overlay_curvature_1_mm.pdf\")\n",
        "print(\"[saved] /content/compare_eval/overlay_Length_mm.pdf\")\n",
        "print(\"[saved] /content/compare_eval/overlay_curvature_1_mm.pdf\")\n",
        "\n",
        "# ---------- LaTeX マクロ ----------\n",
        "def summarize(arr):\n",
        "    arr = arr[np.isfinite(arr)]\n",
        "    return dict(mean=float(np.mean(arr)) if arr.size else float(\"nan\"),\n",
        "                std =float(np.std(arr))  if arr.size else float(\"nan\"),\n",
        "                n=int(arr.size))\n",
        "sums = {\n",
        "  \"length_mm\": {\"base\": summarize(Lb), \"cgtad\": summarize(Lc)},\n",
        "  \"curv_1_per_mm\": {\"base\": summarize(Kb), \"cgtad\": summarize(Kc)}\n",
        "}\n",
        "os.makedirs(\"tex\", exist_ok=True)\n",
        "lines = []\n",
        "lines.append(\"% Auto-generated: Baseline(u=0) vs CGTAD\")\n",
        "def fmt(x,p=3):\n",
        "    if not np.isfinite(x): return '---'\n",
        "    return f\"{x:.{p}f}\" if (1e-4 <= abs(x) < 1e4) else f\"{x:.{p}e}\"\n",
        "lines += [\n",
        "  rf\"\\providecommand{{\\CompNStreams}}{{{len(Lc)}}}\",\n",
        "  rf\"\\providecommand{{\\CompLenMeanBase}}{{{fmt(sums['length_mm']['base']['mean'],2)}}}\",\n",
        "  rf\"\\providecommand{{\\CompLenMeanCG}}{{{fmt(sums['length_mm']['cgtad']['mean'],2)}}}\",\n",
        "  rf\"\\providecommand{{\\CompCurvMeanBase}}{{{fmt(sums['curv_1_per_mm']['base']['mean'],3)}}}\",\n",
        "  rf\"\\providecommand{{\\CompCurvMeanCG}}{{{fmt(sums['curv_1_per_mm']['cgtad']['mean'],3)}}}\",\n",
        "]\n",
        "open(\"tex/compare_macros_generated.tex\",\"w\",encoding=\"utf-8\").write(\"\\n\".join(lines)+\"\\n\")\n",
        "print(\"[macros] tex/compare_macros_generated.tex\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "id": "URrDwgnPogqw",
        "outputId": "c3407902-bf0a-4a3b-ab35-a0e247775f49"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax. Perhaps you forgot a comma? (ipython-input-2966537099.py, line 124)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-2966537099.py\"\u001b[0;36m, line \u001b[0;32m124\u001b[0m\n\u001b[0;31m    return np.array(L, np.array(K, float)\u001b[0m\n\u001b[0m                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === AM reset: DIPY/CSD 用の安定セットに固定 → 強制再起動（Colab） ===\n",
        "# ポイント:\n",
        "# - NumPyは1.26系に固定（2.xは使わない）\n",
        "# - SciPyは1.10.1、pandasは2.2.2に固定\n",
        "# - OpenCVはheadlessの安定版に固定（GUI不要ならこれで十分）\n",
        "\n",
        "%pip -q install --no-input --upgrade --force-reinstall \\\n",
        "  numpy==1.26.4 \\\n",
        "  scipy==1.10.1 \\\n",
        "  pandas==2.2.2 \\\n",
        "  nibabel==5.1.0 \\\n",
        "  dipy==1.8.0 \\\n",
        "  statsmodels==0.14.2 \\\n",
        "  matplotlib==3.8.4 \\\n",
        "  scikit-image==0.21.0 \\\n",
        "  opencv-python-headless==4.9.0.80\n",
        "\n",
        "import os, signal\n",
        "print(\"Pinned versions installed. Restarting runtime to load compiled extensions...\")\n",
        "os.kill(os.getpid(), signal.SIGKILL)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ea9T3LPEIx4r",
        "outputId": "66d11d6b-57a6-487d-adde-8e9743835ded"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "arviz 0.22.0 requires scipy>=1.11.0, but you have scipy 1.10.1 which is incompatible.\n",
            "jax 0.5.3 requires scipy>=1.11.1, but you have scipy 1.10.1 which is incompatible.\n",
            "xarray-einstats 0.9.1 requires scipy>=1.11, but you have scipy 1.10.1 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "jaxlib 0.5.3 requires scipy>=1.11.1, but you have scipy 1.10.1 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "cvxpy 1.6.7 requires scipy>=1.11.0, but you have scipy 1.10.1 which is incompatible.\n",
            "tsfresh 0.21.0 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.10.1 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nccl-cu12==2.21.5; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nccl-cu12 2.23.4 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === リセット一発セル：u=0 Baseline 生成 → CGTADと比較（Colab） ===\n",
        "# 1) 依存とツール\n",
        "!pip -q install -U numpy scipy nibabel dipy statsmodels pandas scikit-image\n",
        "!apt-get -qq update && apt-get -qq install -y dcm2niix >/dev/null\n",
        "\n",
        "import os, re, glob, json, numpy as np, matplotlib.pyplot as plt\n",
        "from nibabel.streamlines import load as sl_load\n",
        "from dipy.io.image import load_nifti\n",
        "from dipy.core.gradients import gradient_table\n",
        "from dipy.segment.mask import median_otsu\n",
        "from dipy.reconst.csdeconv import auto_response_ssst, ConstrainedSphericalDeconvModel\n",
        "from dipy.direction import peaks_from_model\n",
        "from dipy.data import default_sphere\n",
        "from dipy.tracking.stopping_criterion import BinaryStoppingCriterion\n",
        "from dipy.tracking.local_tracking import LocalTracking\n",
        "from dipy.tracking.streamline import Streamlines\n",
        "from dipy.io.streamline import save_trk\n",
        "\n",
        "# 2) 設定（ここだけ編集）：あなたの CGTAD .trk の実パス\n",
        "CGTAD_TRK = \"/content/CGTAD_runs_20250818_0634/B_streamlines.trk\"  # ←必要に応じて修正\n",
        "\n",
        "# 3) CGTAD が見つからなければ自動探索\n",
        "if not os.path.exists(CGTAD_TRK):\n",
        "    cands = glob.glob(\"/content/**/*.trk\", recursive=True)\n",
        "    cands = [p for p in cands if re.search(r\"(B_stream|cgtad|opt)\", os.path.basename(p), re.I)]\n",
        "    if not cands:\n",
        "        raise SystemExit(\"❌ CGTAD .trk が見つかりません。CGTAD_TRK を実パスに直してください。\")\n",
        "    CGTAD_TRK = sorted(cands)[0]\n",
        "print(\"[CGTAD]\", CGTAD_TRK)\n",
        "\n",
        "# 4) CGTAD の種点（最初の頂点）を seeds に採用、ステップ長も推定\n",
        "obj = sl_load(CGTAD_TRK)\n",
        "streams = [np.asarray(s, dtype=np.float64) for s in obj.streamlines if len(s)>=2]\n",
        "seeds_world = [s[0] for s in streams]\n",
        "# ステップ長の中央値（mm）\n",
        "def step_median_mm(s):\n",
        "    d = np.diff(s, axis=0);\n",
        "    return float(np.median(np.linalg.norm(d, axis=1))) if d.size else np.nan\n",
        "STEP_MM = float(np.nanmedian([step_median_mm(s) for s in streams]))\n",
        "if not np.isfinite(STEP_MM): STEP_MM = 0.5\n",
        "print(f\"[seeds] {len(seeds_world)}  [estimated step] {STEP_MM:.3f} mm\")\n",
        "\n",
        "# 5) DWI の取得：既存NIfTIを探す → 無ければ Drive から DICOM候補→自動変換\n",
        "DWI_PATH=BVAL_PATH=BVECS_PATH=None\n",
        "# 5-1) 既存のNIfTI三点セットを /content と Drive から検索\n",
        "roots = [\"/content\", \"/content/drive/MyDrive\", \"/content/drive/Shareddrives\"]\n",
        "def find_files(patterns):\n",
        "    out=[]\n",
        "    for r in roots:\n",
        "        for pat in patterns:\n",
        "            out += glob.glob(os.path.join(r, \"**\", pat), recursive=True)\n",
        "    return sorted(set(out))\n",
        "nii  = find_files([\"*dwi*.nii*\", \"*data.nii*\"])\n",
        "bval = find_files([\"*.bval\", \"*bval*\"])\n",
        "bvec = find_files([\"*.bvec\", \"*bvec*\"])\n",
        "if nii and bval and bvec:\n",
        "    DWI_PATH, BVAL_PATH, BVECS_PATH = nii[0], bval[0], bvec[0]\n",
        "\n",
        "# 5-2) 無ければ Drive をマウントして DICOM を変換\n",
        "if not (DWI_PATH and BVAL_PATH and BVECS_PATH):\n",
        "    try:\n",
        "        from google.colab import drive\n",
        "        if not os.path.ismount(\"/content/drive\"):\n",
        "            drive.mount(\"/content/drive\")\n",
        "    except Exception:\n",
        "        pass\n",
        "    # DICOM候補（枚数が多いフォルダ）\n",
        "    cands=[]\n",
        "    for root in roots[1:]:\n",
        "        for dp, dn, fn in os.walk(root):\n",
        "            n=0\n",
        "            for f in fn:\n",
        "                fl=f.lower()\n",
        "                if fl.endswith((\".dcm\",\".ima\",\".dicom\")) or bool(re.fullmatch(r\"\\d{5,}\", f)):\n",
        "                    n+=1\n",
        "            if n>=30: cands.append((n,dp))\n",
        "    cands.sort(reverse=True)\n",
        "    if cands:\n",
        "        DICOM_DIR=cands[0][1]\n",
        "        print(\"[DICOM candidate]\", DICOM_DIR, f\"(files≈{cands[0][0]})\")\n",
        "        os.makedirs(\"/content/dwi_out\", exist_ok=True)\n",
        "        # 変換\n",
        "        get_ipython().system('dcm2niix -ba y -z y -o /content/dwi_out -f dwi \"{DICOM_DIR}\"')\n",
        "        nii  = sorted(glob.glob(\"/content/dwi_out/*.nii*\"))\n",
        "        bval = sorted(glob.glob(\"/content/dwi_out/*.bval\"))\n",
        "        bvec = sorted(glob.glob(\"/content/dwi_out/*.bvec\"))\n",
        "        if nii and bval and bvec:\n",
        "            DWI_PATH, BVAL_PATH, BVECS_PATH = nii[0], bval[0], bvec[0]\n",
        "\n",
        "if not (DWI_PATH and BVAL_PATH and BVECS_PATH):\n",
        "    raise SystemExit(\"❌ DWI.nii(.gz) / bvals / bvecs が見つかりません。Driveの場所を教えるか、DICOMをzipでアップロードしてください。\")\n",
        "\n",
        "print(\"DWI :\", DWI_PATH)\n",
        "print(\"bvals:\", BVAL_PATH)\n",
        "print(\"bvecs:\", BVECS_PATH)\n",
        "\n",
        "# 6) DIPYで u=0 Baseline 生成（制御なし・同じ種点・推定ステップ長）\n",
        "data, affine = load_nifti(DWI_PATH)\n",
        "bvals = np.loadtxt(BVAL_PATH); bvecs = np.loadtxt(BVECS_PATH)\n",
        "gtab = gradient_table(bvals, bvecs)\n",
        "masked, brainmask = median_otsu(data, numpass=2)\n",
        "response, ratio   = auto_response_ssst(gtab, masked, roi_radius=10, fa_thr=0.7)\n",
        "csd = ConstrainedSphericalDeconvModel(gtab, response, sh_order=8)\n",
        "peaks = peaks_from_model(csd, masked, default_sphere,\n",
        "                         relative_peak_threshold=0.8, min_separation_angle=25,\n",
        "                         mask=brainmask, npeaks=5, normalize_peaks=True)\n",
        "stop = BinaryStoppingCriterion(peaks.gfa > 0.2)\n",
        "\n",
        "streamlines_u0 = Streamlines(LocalTracking(\n",
        "    peaks, stop, seeds_world, affine, step_size=float(STEP_MM), max_cross=1, return_all=False\n",
        "))\n",
        "\n",
        "os.makedirs(\"/content/baseline_eval\", exist_ok=True)\n",
        "BASE_TRK = \"/content/baseline_eval/baseline_u0_sameSeeds.trk\"\n",
        "save_trk(streamlines_u0, BASE_TRK, affine=affine, shape=data.shape[:3])\n",
        "print(f\"[saved baseline] {BASE_TRK}  n={len(streamlines_u0)}\")\n",
        "\n",
        "# 7) 指標（長さ/平均曲率）を読み出し、CGTAD と重ねヒスト → PDF と LaTeXマクロ\n",
        "def load_len_curv(trk):\n",
        "    obj = sl_load(trk); Ls, Ks = [], []\n",
        "    for s in obj.streamlines:\n",
        "        s = np.asarray(s, dtype=np.float64)\n",
        "        if s.shape[0] >= 2:\n",
        "            d = np.diff(s, axis=0); Ls.append(float(np.sum(np.linalg.norm(d, axis=1))))\n",
        "        if s.shape[0] >= 3:\n",
        "            p0,p1,p2=s[:-2],s[1:-1],s[2:]; v1=p1-p0; v2=p2-p1\n",
        "            L1=np.linalg.norm(v1,axis=1)+1e-9; L2=np.linalg.norm(v2,axis=1)+1e-9\n",
        "            ct=np.clip(np.sum(v1*v2,axis=1)/(L1*L2),-1,1); th=np.arccos(ct); smean=0.5*(L1+L2)+1e-9\n",
        "            k=2.0*np.sin(0.5*th)/smean\n",
        "            if k.size: Ks.append(float(np.mean(k)))\n",
        "    return np.asarray(Ls), np.asarray(Ks)\n",
        "\n",
        "Lb,Kb = load_len_curv(BASE_TRK)\n",
        "Lc,Kc = load_len_curv(CGTAD_TRK)\n",
        "\n",
        "def plot_overlay(a,b,title,xlabel,out,bins=64):\n",
        "    lo = min(float(np.min(a)) if a.size else 0, float(np.min(b)) if b.size else 0)\n",
        "    hi = max(float(np.max(a)) if a.size else 1, float(np.max(b)) if b.size else 1)\n",
        "    if not np.isfinite(lo) or not np.isfinite(hi) or lo==hi: lo,hi=0.0,max(1.0,hi if np.isfinite(hi) else 1.0)\n",
        "    edges = np.linspace(lo, hi, bins+1)\n",
        "    plt.figure(figsize=(6,5))\n",
        "    plt.hist(a, bins=edges, alpha=0.5, label=\"Baseline (u=0)\")\n",
        "    plt.hist(b, bins=edges, alpha=0.5, label=\"CGTAD\")\n",
        "    plt.title(title); plt.xlabel(xlabel); plt.ylabel(\"count\"); plt.legend()\n",
        "    os.makedirs(os.path.dirname(out), exist_ok=True)\n",
        "    plt.tight_layout(); plt.savefig(out, bbox_inches=\"tight\"); plt.close()\n",
        "\n",
        "os.makedirs(\"/content/compare_eval\", exist_ok=True)\n",
        "plot_overlay(Lb,Lc,\"Length distribution (u=0 vs CGTAD)\",\"Length (mm)\",\"/content/compare_eval/overlay_Length_mm.pdf\")\n",
        "plot_overlay(Kb,Kc,\"Curvature distribution (u=0 vs CGTAD)\",\"Curvature (1/mm)\",\"/content/compare_eval/overlay_Curvature_1_mm.pdf\")\n",
        "print(\"[saved] /content/compare_eval/overlay_Length_mm.pdf\")\n",
        "print(\"[saved] /content/compare_eval/overlay_Curvature_1_mm.pdf\")\n",
        "\n",
        "def fmt(v,p=3):\n",
        "    if not np.isfinite(v): return '---'\n",
        "    if v!=0 and (abs(v)<1e-4 or abs(v)>=1e4): return f\"{v:.{p}e}\"\n",
        "    return f\"{v:.{p}f}\"\n",
        "def dpp(a,b):\n",
        "    if not (np.isfinite(a) and np.isfinite(b)) or a==0: return '---'\n",
        "    return f\"{100.0*(b-a)/abs(a):.1f}\"\n",
        "def summarize(arr):\n",
        "    return dict(mean=float(np.mean(arr)) if arr.size else float(\"nan\"),\n",
        "                std=float(np.std(arr)) if arr.size else float(\"nan\"),\n",
        "                n=int(arr.size))\n",
        "\n",
        "summs = {\"length_mm\":{\"base\":summarize(Lb),\"cgtad\":summarize(Lc)},\n",
        "         \"curv_1_per_mm\":{\"base\":summarize(Kb),\"cgtad\":summarize(Kc)}}\n",
        "\n",
        "os.makedirs(\"tex\", exist_ok=True)\n",
        "lines = [\n",
        "  \"% Auto-generated: Baseline(u=0 same seeds) vs CGTAD\",\n",
        "  r\"\\providecommand{\\CompLenBase}{%s}\"     % fmt(summs[\"length_mm\"][\"base\"][\"mean\"],2),\n",
        "  r\"\\providecommand{\\CompLenCtl}{%s}\"      % fmt(summs[\"length_mm\"][\"cgtad\"][\"mean\"],2),\n",
        "  r\"\\providecommand{\\CompLenDeltaPct}{%s}\" % dpp(summs[\"length_mm\"][\"base\"][\"mean\"], summs[\"length_mm\"][\"cgtad\"][\"mean\"]),\n",
        "  r\"\\providecommand{\\CompCurvBase}{%s}\"    % fmt(summs[\"curv_1_per_mm\"][\"base\"][\"mean\"],3),\n",
        "  r\"\\providecommand{\\CompCurvCtl}{%s}\"     % fmt(summs[\"curv_1_per_mm\"][\"cgtad\"][\"mean\"],3),\n",
        "  r\"\\providecommand{\\CompCurvDeltaPct}{%s}\"% dpp(summs[\"curv_1_per_mm\"][\"base\"][\"mean\"], summs[\"curv_1_per_mm\"][\"cgtad\"][\"mean\"]),\n",
        "]\n",
        "open(\"tex/compare_macros_generated.tex\",\"w\",encoding=\"utf-8\").write(\"\\n\".join(lines)+\"\\n\")\n",
        "print(\"[macros] tex/compare_macros_generated.tex\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 916
        },
        "id": "XYIPw-zfKEAn",
        "outputId": "1d64f1fc-fc25-4c28-f426-be20f2e32682"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.3.1 which is incompatible.\n",
            "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 2.3.2 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.2 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.2 which is incompatible.\n",
            "cupy-cuda12x 13.3.0 requires numpy<2.3,>=1.22, but you have numpy 2.3.2 which is incompatible.\n",
            "cudf-cu12 25.6.0 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.1 which is incompatible.\n",
            "dask-cudf-cu12 25.6.0 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.1 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.3.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mW: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name '_center' from 'numpy.core._multiarray_umath' (/usr/local/lib/python3.11/dist-packages/numpy/core/_multiarray_umath.cpython-311-x86_64-linux-gnu.so)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2193182093.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnibabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstreamlines\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msl_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_nifti\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradients\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgradient_table\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msegment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmedian_otsu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/dipy/io/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# init for io routines\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdpy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mgradients\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mread_bvals_bvecs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/dipy/io/utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdipy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtesting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecorators\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarning_for_keywords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptpkg\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moptional_package\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/dipy/testing/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtesting\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnpt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtesting\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0massert_array_equal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/testing/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0munittest\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTestCase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_private\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverrides\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_private\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mextbuild\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_private\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/testing/overrides.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \"\"\"\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mumath\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_umath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mufunc\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_ufunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moverrides\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mARRAY_FUNCTIONS\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_array_functions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/_core/umath.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# _ones_like is semi-public, on purpose not added to __all__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# These imports are needed for the strip & replace implementations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m from ._multiarray_umath import (\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0m_UFUNC_API\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0m_add_newdoc_ufunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name '_center' from 'numpy.core._multiarray_umath' (/usr/local/lib/python3.11/dist-packages/numpy/core/_multiarray_umath.cpython-311-x86_64-linux-gnu.so)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 最低限に固定（Colabと互換が取れる組み合わせ）\n",
        "!pip -q install --force-reinstall --no-cache-dir \\\n",
        "  \"numpy==1.26.4\" \"pandas==2.2.2\" \"scipy==1.11.4\" \\\n",
        "  \"nibabel==5.2.1\" \"dipy==1.7.0\" \"scikit-image==0.22.0\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uaVzEqZMLOVr",
        "outputId": "ce08d82a-8fe0-47f9-864b-8327fe60242d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.4/60.4 kB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m286.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m318.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m315.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.4/36.4 MB\u001b[0m \u001b[31m291.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m151.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m95.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.7/14.7 MB\u001b[0m \u001b[31m249.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m356.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m315.8/315.8 kB\u001b[0m \u001b[31m427.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m423.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.5/66.5 kB\u001b[0m \u001b[31m305.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m357.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.9/229.9 kB\u001b[0m \u001b[31m389.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m509.2/509.2 kB\u001b[0m \u001b[31m437.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m230.8/230.8 kB\u001b[0m \u001b[31m362.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m208.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m347.8/347.8 kB\u001b[0m \u001b[31m190.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "tsfresh 0.21.0 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.11.4 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nccl-cu12==2.21.5; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nccl-cu12 2.23.4 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np, dipy, nibabel as nib, scipy\n",
        "print(\"numpy\", np.__version__, \"| dipy\", dipy.__version__, \"| nibabel\", nib.__version__, \"| scipy\", scipy.__version__)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51RPbZcUIi9e",
        "outputId": "205001da-a541-4b4d-89dd-3fecbf76bc94"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numpy 1.26.4 | dipy 1.11.0 | nibabel 5.3.2 | scipy 1.16.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from nibabel.streamlines import load as trk_load\n",
        "\n",
        "def _len_mm(s):\n",
        "    if s.shape[0] < 2: return 0.0\n",
        "    d = np.diff(s, axis=0)\n",
        "    return float(np.linalg.norm(d, axis=1).sum())\n",
        "\n",
        "def _curv_mean(s, eps=1e-9):\n",
        "    if s.shape[0] < 3: return np.nan\n",
        "    p0,p1,p2 = s[:-2], s[1:-1], s[2:]\n",
        "    v1 = p1 - p0; v2 = p2 - p1\n",
        "    L1 = np.linalg.norm(v1, axis=1) + eps\n",
        "    L2 = np.linalg.norm(v2, axis=1) + eps\n",
        "    ct = np.clip(np.sum(v1*v2, axis=1) / (L1*L2), -1, 1)\n",
        "    th = np.arccos(ct); smean = 0.5*(L1+L2) + eps\n",
        "    k = 2.0*np.sin(0.5*th)/smean  # 1/mm\n",
        "    return float(np.nanmean(k)) if k.size else np.nan\n",
        "\n",
        "def extract_arrays(trk_path):\n",
        "    \"\"\"trk から (長さmm配列, 曲率1/mm配列) を返す\"\"\"\n",
        "    obj = trk_load(trk_path)\n",
        "    Ls, Ks = [], []\n",
        "    for s in obj.streamlines:\n",
        "        s = np.asarray(s, dtype=np.float64)\n",
        "        if s.shape[0] >= 2:\n",
        "            Ls.append(_len_mm(s))\n",
        "        if s.shape[0] >= 3:\n",
        "            kv = _curv_mean(s)\n",
        "            if np.isfinite(kv): Ks.append(kv)\n",
        "    return np.array(Ls, dtype=float), np.array(Ks, dtype=float)\n"
      ],
      "metadata": {
        "id": "hJBeI6OexOGl"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# こういう誤記を探します\n",
        "import re, inspect\n",
        "print(re.findall(r\"np\\.array\\(\\s*\\[,\\s*float\", open('/content/*.py','r').read() ))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        },
        "id": "j6sWJ_BtxVAw",
        "outputId": "b70f0ead-22be-4d1f-8ba4-7d88de743aae"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/*.py'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3551039950.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# こういう誤記を探します\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\"np\\.array\\(\\s*\\[,\\s*float\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/*.py'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/*.py'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ← これはダメ：open('/content/*.py')\n",
        "# 置き換え（必要なときだけ実行）:\n",
        "import glob, re\n",
        "hits=[]\n",
        "for p in glob.glob('/content/**/*.py', recursive=True):\n",
        "    try:\n",
        "        txt = open(p, 'r', encoding='utf-8', errors='ignore').read()\n",
        "        if re.search(r\"np\\.array\\(\\s*\\[,\\s*float\", txt):\n",
        "            hits.append(p)\n",
        "    except Exception:\n",
        "        pass\n",
        "print(hits or \"no hits\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wCDemaLCIoz8",
        "outputId": "461f2227-deff-4d46-e4ac-cfb00778b8e7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "no hits\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, numpy as np, matplotlib.pyplot as plt\n",
        "from nibabel.streamlines import load as trk_load\n",
        "\n",
        "BASE_TRK  = \"/content/baseline_eval/baseline_u0_sameSeeds.trk\"  # 生成済みのu=0\n",
        "CGTAD_TRK = \"/content/drive/MyDrive/CGTAD/B_streamlines.trk\"    # あなたのCGTAD\n",
        "\n",
        "assert os.path.exists(CGTAD_TRK), \"CGTAD .trk が見つかりません\"\n",
        "assert os.path.exists(BASE_TRK),  \"ベースライン .trk が見つかりません（先に生成を）\"\n",
        "\n",
        "# 上で定義した extract_arrays を利用\n",
        "Lb, Kb = extract_arrays(BASE_TRK)\n",
        "Lc, Kc = extract_arrays(CGTAD_TRK)\n",
        "print(\"[auto] baseline:\", len(Lb), \" CGTAD:\", len(Lc))\n",
        "\n",
        "def plot_overlay(a,b,title,xlabel,out,bins=64):\n",
        "    plt.figure(figsize=(6.4,5))\n",
        "    lo = float(np.nanmin(np.r_[a,b])) if a.size and b.size else 0.0\n",
        "    hi = float(np.nanmax(np.r_[a,b])) if a.size and b.size else 1.0\n",
        "    lo, hi = max(lo,0.0), max(hi,1e-6)\n",
        "    edges = np.linspace(lo, hi, bins+1)\n",
        "    plt.hist(a, bins=edges, alpha=0.6, label=\"Baseline (u=0)\")\n",
        "    plt.hist(b, bins=edges, alpha=0.6, label=\"CGTAD\")\n",
        "    plt.title(title); plt.xlabel(xlabel); plt.ylabel(\"count\"); plt.legend()\n",
        "    os.makedirs(os.path.dirname(out), exist_ok=True)\n",
        "    plt.tight_layout(); plt.savefig(out, bbox_inches=\"tight\"); plt.close()\n",
        "\n",
        "plot_overlay(Lb,Lc, \"Length distribution (Baseline vs CGTAD)\", \"Length (mm)\",\n",
        "             \"/content/compare_eval/overlay_Length_mm.pdf\")\n",
        "plot_overlay(Kb,Kc, \"Curvature distribution (Baseline vs CGTAD)\", \"Curvature (1/mm)\",\n",
        "             \"/content/compare_eval/overlay_curvature_1_mm.pdf\")\n",
        "print(\"[saved] /content/compare_eval/overlay_Length_mm.pdf\")\n",
        "print(\"[saved] /content/compare_eval/overlay_curvature_1_mm.pdf\")\n",
        "\n",
        "# LaTeX マクロ\n",
        "def summarize(arr):\n",
        "    arr = arr[np.isfinite(arr)]\n",
        "    return dict(mean=float(np.mean(arr)) if arr.size else float(\"nan\"),\n",
        "                std =float(np.std(arr))  if arr.size else float(\"nan\"),\n",
        "                n=int(arr.size))\n",
        "sums = {\"length_mm\":{\"base\":summarize(Lb),\"cgtad\":summarize(Lc)},\n",
        "        \"curv_1_per_mm\":{\"base\":summarize(Kb),\"cgtad\":summarize(Kc)}}\n",
        "\n",
        "def fmt(x,p=3):\n",
        "    if not np.isfinite(x): return '---'\n",
        "    return f\"{x:.{p}f}\" if (1e-4 <= abs(x) < 1e4) else f\"{x:.{p}e}\"\n",
        "\n",
        "os.makedirs(\"tex\", exist_ok=True)\n",
        "lines = [\n",
        "  \"% Auto-generated: Baseline(u=0) vs CGTAD\",\n",
        "  rf\"\\providecommand{{\\CompLenMeanBase}}{{{fmt(sums['length_mm']['base']['mean'],2)}}}\",\n",
        "  rf\"\\providecommand{{\\CompLenMeanCG}}{{{fmt(sums['length_mm']['cgtad']['mean'],2)}}}\",\n",
        "  rf\"\\providecommand{{\\CompCurvMeanBase}}{{{fmt(sums['curv_1_per_mm']['base']['mean'],3)}}}\",\n",
        "  rf\"\\providecommand{{\\CompCurvMeanCG}}{{{fmt(sums['curv_1_per_mm']['cgtad']['mean'],3)}}}\",\n",
        "]\n",
        "open(\"tex/compare_macros_generated.tex\",\"w\",encoding=\"utf-8\").write(\"\\n\".join(lines)+\"\\n\")\n",
        "print(\"[macros] tex/compare_macros_generated.tex\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "id": "fJfNFcvfIfQC",
        "outputId": "95a2af5e-1d42-4972-c59d-72903e1769e0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ベースライン .trk が見つかりません（先に生成を）",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3913451637.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCGTAD_TRK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"CGTAD .trk が見つかりません\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBASE_TRK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;34m\"ベースライン .trk が見つかりません（先に生成を）\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# 上で定義した extract_arrays を利用\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: ベースライン .trk が見つかりません（先に生成を）"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========== TRK 自動検出 ＆ 比較/単独評価 ワンセル ==========\n",
        "import os, glob, numpy as np, matplotlib.pyplot as plt\n",
        "from nibabel.streamlines import load as trk_load\n",
        "\n",
        "# ---- 1) ユーティリティ（長さ/曲率＆抽出） ----\n",
        "def _len_mm(s):\n",
        "    if s.shape[0] < 2: return 0.0\n",
        "    d = np.diff(s, axis=0); return float(np.linalg.norm(d, axis=1).sum())\n",
        "\n",
        "def _curv_mean(s, eps=1e-9):\n",
        "    if s.shape[0] < 3: return np.nan\n",
        "    p0,p1,p2 = s[:-2], s[1:-1], s[2:]\n",
        "    v1 = p1 - p0; v2 = p2 - p1\n",
        "    L1 = np.linalg.norm(v1, axis=1) + eps\n",
        "    L2 = np.linalg.norm(v2, axis=1) + eps\n",
        "    ct = np.clip(np.sum(v1*v2, axis=1)/(L1*L2), -1, 1)\n",
        "    th = np.arccos(ct); smean = 0.5*(L1+L2) + eps\n",
        "    k = 2.0*np.sin(0.5*th)/smean  # 1/mm\n",
        "    return float(np.nanmean(k)) if np.isfinite(k).all() else np.nan\n",
        "\n",
        "def extract_arrays(trk_path):\n",
        "    obj = trk_load(trk_path)\n",
        "    Ls, Ks = [], []\n",
        "    for s in obj.streamlines:\n",
        "        s = np.asarray(s, dtype=np.float64)\n",
        "        if s.shape[0] >= 2: Ls.append(_len_mm(s))\n",
        "        if s.shape[0] >= 3:\n",
        "            kv = _curv_mean(s)\n",
        "            if np.isfinite(kv): Ks.append(kv)\n",
        "    return np.array(Ls, dtype=float), np.array(Ks, dtype=float)\n",
        "\n",
        "def summarize(arr):\n",
        "    arr = arr[np.isfinite(arr)]\n",
        "    return dict(mean=float(np.mean(arr)) if arr.size else float(\"nan\"),\n",
        "                std =float(np.std(arr))  if arr.size else float(\"nan\"),\n",
        "                n=int(arr.size))\n",
        "\n",
        "def fmt(x,p=3):\n",
        "    if not np.isfinite(x): return '---'\n",
        "    return f\"{x:.{p}f}\" if (1e-4 <= abs(x) < 1e4) else f\"{x:.{p}e}\"\n",
        "\n",
        "def plot_overlay(a,b,title,xlabel,out,bins=64):\n",
        "    plt.figure(figsize=(6.4,5))\n",
        "    if a.size and b.size:\n",
        "        lo = float(np.nanmin(np.r_[a,b])); hi = float(np.nanmax(np.r_[a,b]))\n",
        "    elif a.size:\n",
        "        lo = float(np.nanmin(a)); hi = float(np.nanmax(a))\n",
        "    elif b.size:\n",
        "        lo = float(np.nanmin(b)); hi = float(np.nanmax(b))\n",
        "    else:\n",
        "        lo, hi = 0.0, 1.0\n",
        "    lo, hi = max(lo,0.0), max(hi,1e-6)\n",
        "    edges = np.linspace(lo, hi, bins+1)\n",
        "    if a.size: plt.hist(a, bins=edges, alpha=0.6, label=\"Baseline (u=0)\")\n",
        "    if b.size: plt.hist(b, bins=edges, alpha=0.6, label=\"CGTAD\")\n",
        "    plt.title(title); plt.xlabel(xlabel); plt.ylabel(\"count\")\n",
        "    if a.size and b.size: plt.legend()\n",
        "    os.makedirs(os.path.dirname(out), exist_ok=True)\n",
        "    plt.tight_layout(); plt.savefig(out, bbox_inches=\"tight\"); plt.close()\n",
        "    print(\"[saved]\", out)\n",
        "\n",
        "# ---- 2) .trk を自動検出（/content と Drive） ----\n",
        "cands = sorted(set(\n",
        "    glob.glob(\"/content/**/*.trk\", recursive=True) +\n",
        "    glob.glob(\"/content/drive/**/*.trk\", recursive=True)\n",
        "))\n",
        "print(\"trk candidates:\"); [print(\" -\", p) for p in cands]\n",
        "\n",
        "# ヒューリスティックで拾う\n",
        "CGTAD_TRK = next((p for p in cands\n",
        "                  if os.path.basename(p).lower().startswith((\"b_stream\",\"cgtad\"))), None)\n",
        "BASE_TRK  = next((p for p in cands\n",
        "                  if \"baseline\" in os.path.basename(p).lower()), None)\n",
        "\n",
        "# 手元のファイル状況に合わせて最後の救済（左ツリーに見えているやつ）\n",
        "if CGTAD_TRK is None and os.path.exists(\"/content/B_streamlines.trk\"):\n",
        "    CGTAD_TRK = \"/content/B_streamlines.trk\"\n",
        "\n",
        "print(\"\\nPicked:\")\n",
        "print(\"  CGTAD :\", CGTAD_TRK)\n",
        "print(\"  BASE  :\", BASE_TRK, \"\\n\")\n",
        "\n",
        "# ---- 3) 評価・出力 ----\n",
        "os.makedirs(\"tex\", exist_ok=True)\n",
        "\n",
        "if CGTAD_TRK and BASE_TRK and os.path.exists(CGTAD_TRK) and os.path.exists(BASE_TRK):\n",
        "    # 比較\n",
        "    Lb,Kb = extract_arrays(BASE_TRK)\n",
        "    Lc,Kc = extract_arrays(CGTAD_TRK)\n",
        "    print(\"[counts] baseline:\", len(Lb), \" CGTAD:\", len(Lc))\n",
        "    plot_overlay(Lb,Lc, \"Length distribution (Baseline vs CGTAD)\", \"Length (mm)\",\n",
        "                 \"/content/compare_eval/overlay_Length_mm.pdf\")\n",
        "    plot_overlay(Kb,Kc, \"Curvature distribution (Baseline vs CGTAD)\", \"Curvature (1/mm)\",\n",
        "                 \"/content/compare_eval/overlay_curvature_1_mm.pdf\")\n",
        "\n",
        "    sums = {\"length_mm\":{\"base\":summarize(Lb),\"cgtad\":summarize(Lc)},\n",
        "            \"curv_1_per_mm\":{\"base\":summarize(Kb),\"cgtad\":summarize(Kc)}}\n",
        "    lines = [\n",
        "      \"% Auto-generated: Baseline(u=0) vs CGTAD\",\n",
        "      rf\"\\providecommand{{\\CompLenMeanBase}}{{{fmt(sums['length_mm']['base']['mean'],2)}}}\",\n",
        "      rf\"\\providecommand{{\\CompLenMeanCG}}{{{fmt(sums['length_mm']['cgtad']['mean'],2)}}}\",\n",
        "      rf\"\\providecommand{{\\CompCurvMeanBase}}{{{fmt(sums['curv_1_per_mm']['base']['mean'],3)}}}\",\n",
        "      rf\"\\providecommand{{\\CompCurvMeanCG}}{{{fmt(sums['curv_1_per_mm']['cgtad']['mean'],3)}}}\",\n",
        "    ]\n",
        "    open(\"tex/compare_macros_generated.tex\",\"w\",encoding=\"utf-8\").write(\"\\n\".join(lines)+\"\\n\")\n",
        "    print(\"[macros] tex/compare_macros_generated.tex\")\n",
        "\n",
        "elif CGTAD_TRK and os.path.exists(CGTAD_TRK):\n",
        "    # CGTAD 単独（Baseline 未入手時の暫定）\n",
        "    Lc,Kc = extract_arrays(CGTAD_TRK)\n",
        "    print(\"[counts] CGTAD:\", len(Lc))\n",
        "    plot_overlay(np.array([]),Lc, \"CGTAD: Length distribution\", \"Length (mm)\",\n",
        "                 \"/content/compare_eval/cgtad_Length_mm.pdf\")\n",
        "    plot_overlay(np.array([]),Kc, \"CGTAD: Curvature distribution\", \"Curvature (1/mm)\",\n",
        "                 \"/content/compare_eval/cgtad_curvature_1_mm.pdf\")\n",
        "\n",
        "    sums = {\"length_mm\":{\"cgtad\":summarize(Lc)},\n",
        "            \"curv_1_per_mm\":{\"cgtad\":summarize(Kc)}}\n",
        "    lines = [\n",
        "      \"% Auto-generated: CGTAD only\",\n",
        "      rf\"\\providecommand{{\\CGOnlyLenMean}}{{{fmt(sums['length_mm']['cgtad']['mean'],2)}}}\",\n",
        "      rf\"\\providecommand{{\\CGOnlyCurvMean}}{{{fmt(sums['curv_1_per_mm']['cgtad']['mean'],3)}}}\",\n",
        "    ]\n",
        "    open(\"tex/cgtad_only_macros_generated.tex\",\"w\",encoding=\"utf-8\").write(\"\\n\".join(lines)+\"\\n\")\n",
        "    print(\"[macros] tex/cgtad_only_macros_generated.tex\")\n",
        "    print(\"\\n※ Baseline(u=0) が無いので比較はスキップ。後で u=0 を作れば重ね図も出せます。\")\n",
        "else:\n",
        "    raise SystemExit(\"❌ .trk が見つかりません。左ツリーの位置を確認して下さい。\")\n",
        "# ==========================================================\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUVeO8ray1Gl",
        "outputId": "59bc12c1-91bd-460a-e05d-859523c78156"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trk candidates:\n",
            " - /content/B_streamlines.trk\n",
            " - /content/drive/MyDrive/CGTAD/B_streamlines.trk\n",
            "\n",
            "Picked:\n",
            "  CGTAD : /content/B_streamlines.trk\n",
            "  BASE  : None \n",
            "\n",
            "[counts] CGTAD: 197959\n",
            "[saved] /content/compare_eval/cgtad_Length_mm.pdf\n",
            "[saved] /content/compare_eval/cgtad_curvature_1_mm.pdf\n",
            "[macros] tex/cgtad_only_macros_generated.tex\n",
            "\n",
            "※ Baseline(u=0) が無いので比較はスキップ。後で u=0 を作れば重ね図も出せます。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Stanford HARDI を取得して Baseline(u=0) 生成 → 既存の比較セルが拾える場所に保存 ===\n",
        "import os, numpy as np\n",
        "from dipy.data import get_fnames\n",
        "from dipy.io.image import load_nifti, save_nifti\n",
        "from dipy.core.gradients import gradient_table\n",
        "from dipy.segment.mask import median_otsu\n",
        "from dipy.reconst.csdeconv import auto_response_ssst, ConstrainedSphericalDeconvModel\n",
        "from dipy.direction import peaks_from_model\n",
        "from dipy.tracking.local_tracking import LocalTracking\n",
        "from dipy.tracking.stopping_criterion import BinaryStoppingCriterion\n",
        "from dipy.tracking.streamline import Streamlines\n",
        "from dipy.io.streamline import save_trk\n",
        "\n",
        "# 1) データ取得（約 ~100MB）\n",
        "fraw, fbval, fbvec = get_fnames('stanford_hardi')\n",
        "\n",
        "# 2) 前処理→CSD→追跡（u=0: 制御なし）\n",
        "data, affine = load_nifti(fraw)\n",
        "bvals = np.loadtxt(fbval); bvecs = np.loadtxt(fbvec)\n",
        "gtab  = gradient_table(bvals, bvecs)\n",
        "\n",
        "maskdata, mask = median_otsu(data, vol_idx=np.where(bvals>50)[0], numpass=2)\n",
        "response, ratio = auto_response_ssst(gtab, maskdata, 10, 0.7)\n",
        "csd = ConstrainedSphericalDeconvModel(gtab, response)\n",
        "peaks = peaks_from_model(model=csd, data=maskdata, sphere=None,\n",
        "                         relative_peak_threshold=0.5, min_separation_angle=25,\n",
        "                         mask=mask, return_sh=False, normalize_peaks=True)\n",
        "\n",
        "stop = BinaryStoppingCriterion(mask)\n",
        "seeds = np.argwhere(mask)\n",
        "STEP_MM = 0.5\n",
        "streamlines = Streamlines(LocalTracking(peaks, stop, seeds, affine,\n",
        "                                        step_size=STEP_MM, max_cross=1, return_all=False))\n",
        "\n",
        "os.makedirs(\"/content\", exist_ok=True)\n",
        "BASE_TRK = \"/content/baseline_u0.trk\"\n",
        "save_trk(Streamlines(streamlines), BASE_TRK, affine=affine, shape=data.shape[:3])\n",
        "print(\"[saved baseline]\", BASE_TRK, \"n=\", len(streamlines))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354,
          "referenced_widgets": [
            "47c201d64f6346da82f2648929290b5b",
            "1afda2e4eedd424d8ba52c7388adcd0a",
            "9e313dd59c494c17b4215a28323f0483",
            "096782446d8145ea81a7e41b60b67244",
            "72b32e4a4d3d420f933da9b159288682",
            "0b06c612c40d495a895eb336e5136300",
            "534e4865192e4f9cb86a3cf79c799535",
            "0bc3aef839fd4ab9ab446d8a0e2d14dc",
            "9a2868387d9f41b5be37c5a2d50ebf47",
            "d7254b41dce045f5b95d26721f2b64fa",
            "e609ba3ac5e140b19aa401546c2562e9",
            "3e8b14242c0d4f35b1fa40b553bea719",
            "ab72f5c0c492492eab624541d8d215d7",
            "62fb248c6a4b41a8bda12e08c8987bdc",
            "0840ef6af2094f619955780d6154738a",
            "782153b3f1dd4a7c8aca5faaa80816c0",
            "929f66cd9dcd4c6c83e80593055cbf71",
            "fa338f02d37b4232a86f898ae7632ab9",
            "0f094100d09848a0ba43c3f635254a4d",
            "2ac506d8fde44e039d0a1c903b984015",
            "03561f28d06d44e985e7c570f880f649",
            "c4d19e3d6ad84555853dd017e9cdc921",
            "e86709845f3e4c0eae0d79b66cab4b31",
            "d12847052f804506a0878c47ec1114bb",
            "7bef755a3f5d4168a48cf42d70f46b3c",
            "6161029ed68e4a9d8dae18e3d33c40c1",
            "6bf3cde2478b44538535a8d144c82d9b",
            "6ccac9c632884caca51da06a8849c47e",
            "22324d41bb4a492dbc9a504c360c37b2",
            "a0ff7a98e44c420986950c3c09f4f6a6",
            "1a0d2c37971d4095be7f3f899053725b",
            "7e5faf3c508a4f7a8ad44842e5c3a3f3",
            "ebe37b6899964869be8201f8f7d987d3"
          ]
        },
        "id": "miLrlUVj4co3",
        "outputId": "d5144670-ef5e-4558-cf7b-7eb2d147f5b2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/5578 [00:00<?, ? MB/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "47c201d64f6346da82f2648929290b5b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ? MB/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3e8b14242c0d4f35b1fa40b553bea719"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ? MB/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e86709845f3e4c0eae0d79b66cab4b31"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "auto_response_ssst() got an unexpected keyword argument 'roi_radius'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1858628106.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mmaskdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmedian_otsu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvol_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbvals\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumpass\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mratio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mauto_response_ssst\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgtab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaskdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroi_radius\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfa_thr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0mcsd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConstrainedSphericalDeconvModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgtab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m peaks = peaks_from_model(model=csd, data=maskdata, sphere=None,\n",
            "\u001b[0;31mTypeError\u001b[0m: auto_response_ssst() got an unexpected keyword argument 'roi_radius'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === 修正一発セル：auto_response_ssst と peaks_from_model を互換呼び出しに統一 ===\n",
        "# 既に data/mask/maskdata/gtab/affine が定義済みならそれを利用。\n",
        "# 未定義なら Stanford HARDI を自動取得して実行します。\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# 必要モジュール\n",
        "from dipy.reconst.csdeconv import auto_response_ssst, ConstrainedSphericalDeconvModel\n",
        "from dipy.direction import peaks_from_model\n",
        "from dipy.data import default_sphere\n",
        "from dipy.tracking import utils\n",
        "from dipy.tracking.local_tracking import LocalTracking\n",
        "from dipy.tracking.stopping_criterion import BinaryStoppingCriterion\n",
        "from dipy.tracking.streamline import Streamlines\n",
        "from dipy.io.streamline import save_trk\n",
        "\n",
        "# ---- 未定義ならデータ読み込み（Stanford HARDI）----\n",
        "try:\n",
        "    data, mask, maskdata, gtab, affine  # 参照して存在チェック\n",
        "except NameError:\n",
        "    from dipy.data import get_fnames\n",
        "    from dipy.io.image import load_nifti\n",
        "    from dipy.segment.mask import median_otsu\n",
        "    from dipy.core.gradients import gradient_table\n",
        "\n",
        "    dwi_f, bval_f, bvec_f = get_fnames('stanford_hardi')\n",
        "    data, affine = load_nifti(dwi_f)\n",
        "    bvals = np.loadtxt(bval_f)\n",
        "    bvecs_raw = np.loadtxt(bvec_f)\n",
        "    bvecs = bvecs_raw.T if bvecs_raw.shape[0] == 3 else bvecs_raw\n",
        "    gtab = gradient_table(bvals, bvecs)\n",
        "\n",
        "    b0_idx = np.where(bvals < 50)[0]\n",
        "    maskdata, mask = median_otsu(data, vol_idx=b0_idx, numpass=2)\n",
        "\n",
        "# ---- 1) auto_response_ssst（古い dipy はキーワード不可なので位置引数で）----\n",
        "#    デフォルト相当: roi_radius=10, fa_thr=0.7\n",
        "response, ratio = auto_response_ssst(gtab, maskdata, 10, 0.7)\n",
        "\n",
        "# ---- 2) CSD モデル ----\n",
        "csd = ConstrainedSphericalDeconvModel(gtab, response)\n",
        "\n",
        "# ---- 3) peaks_from_model：sphere を default_sphere に明示 ----\n",
        "peaks = peaks_from_model(\n",
        "    model=csd,\n",
        "    data=maskdata,\n",
        "    sphere=default_sphere,\n",
        "    relative_peak_threshold=0.5,\n",
        "    min_separation_angle=25,\n",
        "    mask=mask,\n",
        "    return_sh=False,\n",
        "    normalize_peaks=True,\n",
        ")\n",
        "\n",
        "# ---- 4) u=0 のトラッキング（制御なし）----\n",
        "STEP_MM = 0.5\n",
        "seeds = utils.seeds_from_mask(mask, density=1, affine=affine)\n",
        "stop = BinaryStoppingCriterion(mask)\n",
        "streamlines = Streamlines(LocalTracking(peaks, stop, seeds, affine, step_size=STEP_MM))\n",
        "\n",
        "# ---- 5) 保存 ----\n",
        "out_trk = \"/content/baseline_u0.trk\"\n",
        "save_trk(streamlines, out_trk, affine=affine, shape=data.shape[:3])\n",
        "print(f\"[saved] {out_trk}  | n={len(streamlines):,}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "id": "-0rXZqs8DNpT",
        "outputId": "42e605a4-9456-4a66-8475-ab15af4a6bba"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "len() of unsized object",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3681216512.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m# ---- 1) auto_response_ssst（古い dipy はキーワード不可なので位置引数で）----\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;31m#    デフォルト相当: roi_radius=10, fa_thr=0.7\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mratio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mauto_response_ssst\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgtab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaskdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;31m# ---- 2) CSD モデル ----\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/dipy/reconst/csdeconv.py\u001b[0m in \u001b[0;36mauto_response_ssst\u001b[0;34m(gtab, data, roi_center, roi_radii, fa_thr)\u001b[0m\n\u001b[1;32m   1054\u001b[0m     \"\"\"\n\u001b[1;32m   1055\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1056\u001b[0;31m     \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask_for_response_ssst\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgtab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroi_center\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroi_radii\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfa_thr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m     \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mratio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse_from_mask_ssst\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgtab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/dipy/reconst/csdeconv.py\u001b[0m in \u001b[0;36mmask_for_response_ssst\u001b[0;34m(gtab, data, roi_center, roi_radii, fa_thr)\u001b[0m\n\u001b[1;32m    936\u001b[0m         \u001b[0mroi_center\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 938\u001b[0;31m     roi_radii = _roi_in_volume(data.shape, np.asarray(roi_center),\n\u001b[0m\u001b[1;32m    939\u001b[0m                                np.asarray(roi_radii))\n\u001b[1;32m    940\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/dipy/reconst/utils.py\u001b[0m in \u001b[0;36m_roi_in_volume\u001b[0;34m(data_shape, roi_center, roi_radii)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \"\"\"\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroi_center\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0minf_lim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroi_center\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mroi_radii\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0msup_lim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroi_center\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mroi_radii\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: len() of unsized object"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === 修正一発セル：u=0 Baseline 生成（ROI半径を3タプルに） ===\n",
        "import numpy as np\n",
        "from dipy.reconst.csdeconv import auto_response_ssst, ConstrainedSphericalDeconvModel\n",
        "from dipy.direction import peaks_from_model\n",
        "from dipy.data import default_sphere, get_fnames\n",
        "from dipy.io.image import load_nifti\n",
        "from dipy.segment.mask import median_otsu\n",
        "from dipy.core.gradients import gradient_table\n",
        "from dipy.tracking import utils\n",
        "from dipy.tracking.local_tracking import LocalTracking\n",
        "from dipy.tracking.stopping_criterion import BinaryStoppingCriterion\n",
        "from dipy.tracking.streamline import Streamlines\n",
        "from dipy.io.streamline import save_trk\n",
        "\n",
        "# ---- データ未定義なら Stanford HARDI を取得 ----\n",
        "try:\n",
        "    data, mask, maskdata, gtab, affine  # 存在チェック\n",
        "except NameError:\n",
        "    dwi_f, bval_f, bvec_f = get_fnames('stanford_hardi')\n",
        "    data, affine = load_nifti(dwi_f)\n",
        "    bvals = np.loadtxt(bval_f)\n",
        "    bvecs_raw = np.loadtxt(bvec_f)\n",
        "    bvecs = bvecs_raw.T if bvecs_raw.shape[0] == 3 else bvecs_raw\n",
        "    gtab = gradient_table(bvals, bvecs)\n",
        "    b0_idx = np.where(bvals < 50)[0]\n",
        "    maskdata, mask = median_otsu(data, vol_idx=b0_idx, numpass=2)\n",
        "\n",
        "# ---- 1) auto_response_ssst：ROI半径を (10,10,10) に ----\n",
        "response, ratio = auto_response_ssst(gtab, maskdata, (10, 10, 10), 0.7)\n",
        "\n",
        "# ---- 2) CSD モデル ----\n",
        "csd = ConstrainedSphericalDeconvModel(gtab, response)\n",
        "\n",
        "# ---- 3) Peaks 抽出（sphere を明示）----\n",
        "peaks = peaks_from_model(\n",
        "    model=csd,\n",
        "    data=maskdata,\n",
        "    sphere=default_sphere,\n",
        "    relative_peak_threshold=0.5,\n",
        "    min_separation_angle=25,\n",
        "    mask=mask,\n",
        "    return_sh=False,\n",
        "    normalize_peaks=True,\n",
        ")\n",
        "\n",
        "# ---- 4) u=0 トラッキング ----\n",
        "STEP_MM = 0.5\n",
        "seeds = utils.seeds_from_mask(mask, density=1, affine=affine)\n",
        "stop = BinaryStoppingCriterion(mask)\n",
        "streamlines = Streamlines(LocalTracking(peaks, stop, seeds, affine, step_size=STEP_MM))\n",
        "\n",
        "# ---- 5) 保存 ----\n",
        "out_trk = \"/content/baseline_u0.trk\"\n",
        "save_trk(streamlines, out_trk, affine=affine, shape=data.shape[:3])\n",
        "print(f\"[saved] {out_trk}  | n={len(streamlines):,}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Nypb7cKvDzZ2",
        "outputId": "a77be2c9-2b22-4a65-fd7e-78112bf85d3c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/dipy/reconst/csdeconv.py:954: UserWarning: No voxel with a FA higher than 0.7 were found.\n",
            "        Try a larger roi or a lower threshold.\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/dipy/reconst/csdeconv.py:1009: UserWarning: No voxel in mask with value > 0 were found.\n",
            "  warnings.warn(msg, UserWarning)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Input must be 1- or 2-d.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-693441150.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;31m# ---- 2) CSD モデル ----\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mcsd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConstrainedSphericalDeconvModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgtab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m# ---- 3) Peaks 抽出（sphere を明示）----\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/dipy/reconst/csdeconv.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, gtab, response, reg_sphere, sh_order, lambda_, tau, convergence)\u001b[0m\n\u001b[1;32m    264\u001b[0m             \u001b[0mm_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m             self.S_r = estimate_response(gtab, self.response[0],\n\u001b[0m\u001b[1;32m    267\u001b[0m                                          self.response[1])\n\u001b[1;32m    268\u001b[0m             r_sh = np.linalg.lstsq(self.B_dwi, self.S_r[self._where_dwi],\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/dipy/reconst/csdeconv.py\u001b[0m in \u001b[0;36mestimate_response\u001b[0;34m(gtab, evals, S0)\u001b[0m\n\u001b[1;32m    461\u001b[0m                       [1, 0, 0]])\n\u001b[1;32m    462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msingle_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgtab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevecs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msnr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/dipy/sims/voxel.py\u001b[0m in \u001b[0;36msingle_tensor\u001b[0;34m(gtab, S0, evals, evecs, snr)\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0mR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevecs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[0mS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m     \u001b[0mD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mgtab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbtens\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/lib/twodim_base.py\u001b[0m in \u001b[0;36mdiag\u001b[0;34m(v, k)\u001b[0m\n\u001b[1;32m    301\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdiagonal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 303\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Input must be 1- or 2-d.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input must be 1- or 2-d."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === u=0 Baseline 生成：auto_response が失敗しても自動でフォールバックする完成版 ===\n",
        "import numpy as np\n",
        "from dipy.io.image import load_nifti\n",
        "from dipy.core.gradients import gradient_table\n",
        "from dipy.segment.mask import median_otsu\n",
        "from dipy.data import default_sphere, get_fnames\n",
        "from dipy.reconst.csdeconv import auto_response_ssst, ConstrainedSphericalDeconvModel\n",
        "from dipy.reconst.dti import TensorModel\n",
        "from dipy.direction import peaks_from_model\n",
        "from dipy.tracking import utils\n",
        "from dipy.tracking.stopping_criterion import BinaryStoppingCriterion\n",
        "from dipy.tracking.local_tracking import LocalTracking\n",
        "from dipy.tracking.streamline import Streamlines\n",
        "from dipy.io.streamline import save_trk\n",
        "\n",
        "# --- 任意で自前データに置き換え可能（None のままなら stanford_hardi を使用） ---\n",
        "DWI_PATH = None  # 例: \"/content/drive/MyDrive/xxx/dwi.nii.gz\"\n",
        "BVAL_PATH = None # 例: \"/content/drive/MyDrive/xxx/bvals\"\n",
        "BVEC_PATH = None # 例: \"/content/drive/MyDrive/xxx/bvecs\"\n",
        "\n",
        "def load_dataset():\n",
        "    if DWI_PATH and BVAL_PATH and BVEC_PATH:\n",
        "        data, affine = load_nifti(DWI_PATH)\n",
        "        bvals = np.loadtxt(BVAL_PATH)\n",
        "        bvecs_raw = np.loadtxt(BVEC_PATH)\n",
        "        bvecs = bvecs_raw.T if bvecs_raw.shape[0] == 3 else bvecs_raw\n",
        "        gtab = gradient_table(bvals, bvecs)\n",
        "    else:\n",
        "        dwi_f, bval_f, bvec_f = get_fnames('stanford_hardi')\n",
        "        data, affine = load_nifti(dwi_f)\n",
        "        bvals = np.loadtxt(bval_f)\n",
        "        bvecs_raw = np.loadtxt(bvec_f)\n",
        "        bvecs = bvecs_raw.T if bvecs_raw.shape[0] == 3 else bvecs_raw\n",
        "        gtab = gradient_table(bvals, bvecs)\n",
        "    return data, affine, gtab, bvals\n",
        "\n",
        "def center_roi_mask(mask, radius):\n",
        "    \"\"\"マスクの外接ボックス中心付近の立方体ROIを返す\"\"\"\n",
        "    inds = np.array(np.where(mask))\n",
        "    if inds.size == 0:\n",
        "        return np.zeros_like(mask, dtype=bool)\n",
        "    mins = inds.min(axis=1)\n",
        "    maxs = inds.max(axis=1)\n",
        "    ctr  = ((mins + maxs) // 2).astype(int)\n",
        "    xs = [max(0, ctr[0]-radius), min(mask.shape[0], ctr[0]+radius+1)]\n",
        "    ys = [max(0, ctr[1]-radius), min(mask.shape[1], ctr[1]+radius+1)]\n",
        "    zs = [max(0, ctr[2]-radius), min(mask.shape[2], ctr[2]+radius+1)]\n",
        "    roi = np.zeros_like(mask, dtype=bool)\n",
        "    roi[xs[0]:xs[1], ys[0]:ys[1], zs[0]:zs[1]] = True\n",
        "    return roi & mask\n",
        "\n",
        "def robust_response(gtab, data, mask):\n",
        "    \"\"\"\n",
        "    まず auto_response_ssst を試し、ダメなら DTI を小ROIでフィットして\n",
        "    response(evals, S0) を推定して返す。\n",
        "    \"\"\"\n",
        "    # 1) auto_response_ssst を閾値/半径を変えながら試行\n",
        "    for fa_thr in (0.7, 0.6, 0.5, 0.4, 0.3):\n",
        "        for rad in ((10,10,10), (12,12,12), (15,15,15)):\n",
        "            try:\n",
        "                resp, ratio = auto_response_ssst(gtab, data, rad, fa_thr)\n",
        "                # DIPY では resp が Response オブジェクト or (evals,S0) 互換\n",
        "                evals = getattr(resp, \"evals\", None) or resp[0]\n",
        "                S0    = getattr(resp, \"S0\",    None) or resp[1]\n",
        "                evals = np.asarray(evals).ravel()\n",
        "                if evals.size == 3 and np.all(np.isfinite(evals)) and np.isfinite(S0) and S0 > 0:\n",
        "                    print(f\"[auto_response] OK  fa_thr={fa_thr}, roi={rad}, evals={evals}, S0={S0:.1f}\")\n",
        "                    return (evals, S0)\n",
        "            except Exception as e:\n",
        "                # 次の設定で再試行\n",
        "                continue\n",
        "\n",
        "    # 2) フォールバック：DTI を ROI でフィットし median を使う\n",
        "    b0 = gtab.bvals < 50\n",
        "    S0_vol = data[..., b0].mean(-1)\n",
        "    roi = center_roi_mask(mask, radius=12)\n",
        "    if roi.sum() < 100:\n",
        "        roi = center_roi_mask(mask, radius=16)\n",
        "    if roi.sum() < 50:\n",
        "        # 最終手段：全マスク\n",
        "        roi = mask\n",
        "\n",
        "    ten = TensorModel(gtab).fit(data, mask=roi)\n",
        "    evals_roi = np.asarray(ten.evals)[roi]  # (N,3)\n",
        "    if evals_roi.size == 0:\n",
        "        # 典型的なWM値にフォールバック（mm^2/s）\n",
        "        evals_med = np.array([1.7e-3, 3.0e-4, 3.0e-4])\n",
        "    else:\n",
        "        evals_med = np.nanmedian(evals_roi, axis=0)\n",
        "    S0_med = float(np.nanmedian(S0_vol[roi])) if roi.any() else float(np.nanmedian(S0_vol))\n",
        "\n",
        "    print(f\"[fallback DTI] evals={evals_med}, S0={S0_med:.1f}, roi_vox={int(roi.sum())}\")\n",
        "    return (evals_med, S0_med)\n",
        "\n",
        "# ---- パイプライン ----\n",
        "data, affine, gtab, bvals = load_dataset()\n",
        "b0_idx = np.where(bvals < 50)[0]\n",
        "maskdata, mask = median_otsu(data, vol_idx=b0_idx, numpass=2)\n",
        "\n",
        "response = robust_response(gtab, maskdata, mask)\n",
        "csd = ConstrainedSphericalDeconvModel(gtab, response)\n",
        "\n",
        "peaks = peaks_from_model(\n",
        "    model=csd,\n",
        "    data=maskdata,\n",
        "    sphere=default_sphere,\n",
        "    relative_peak_threshold=0.5,\n",
        "    min_separation_angle=25,\n",
        "    mask=mask,\n",
        "    return_sh=False,\n",
        "    normalize_peaks=True,\n",
        ")\n",
        "\n",
        "STEP_MM = 0.5\n",
        "seeds = utils.seeds_from_mask(mask, density=1, affine=affine)\n",
        "stop = BinaryStoppingCriterion(mask)\n",
        "streamlines = Streamlines(LocalTracking(peaks, stop, seeds, affine, step_size=STEP_MM))\n",
        "\n",
        "out_trk = \"/content/baseline_u0.trk\"\n",
        "save_trk(streamlines, out_trk, affine=affine, shape=data.shape[:3])\n",
        "print(f\"[saved] {out_trk} | n={len(streamlines):,}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "id": "s9u_YMqrEz2t",
        "outputId": "5797e6c4-70be-4e11-f3b1-884ece3d7d3d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fallback DTI] evals=[0.00111117 0.00066572 0.00053278], S0=471.8, roi_vox=14482\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "save_generator.<locals>.f_gen() got an unexpected keyword argument 'affine'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4020842468.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0mout_trk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/baseline_u0.trk\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m \u001b[0msave_trk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstreamlines\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_trk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maffine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maffine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"[saved] {out_trk} | n={len(streamlines):,}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: save_generator.<locals>.f_gen() got an unexpected keyword argument 'affine'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== QC for /content/baseline.trk =====\n",
        "import os, numpy as np\n",
        "from dipy.io.streamline import load_trk\n",
        "from dipy.io.stateful_tractogram import Space\n",
        "from dipy.tracking.streamline import length\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "trk = \"/content/baseline.trk\"\n",
        "if not os.path.exists(trk):\n",
        "    raise FileNotFoundError(f\"not found: {trk}\")\n",
        "\n",
        "sft = load_trk(trk, \"same\")\n",
        "sft.to_space(Space.RASMM)  # 長さを mm で評価\n",
        "sl = sft.streamlines\n",
        "n = len(sl)\n",
        "lens = np.array([length(s) for s in sl]) if n else np.array([])\n",
        "\n",
        "print(f\"[OK] streamlines: {n}\")\n",
        "if n:\n",
        "    print(f\" length (mm): mean={lens.mean():.1f} ± {lens.std():.1f}  \"\n",
        "          f\"min/max={lens.min():.1f}/{lens.max():.1f}\")\n",
        "\n",
        "    plt.figure()\n",
        "    plt.hist(lens, bins=30)\n",
        "    plt.xlabel(\"Streamline length (mm)\")\n",
        "    plt.ylabel(\"Count\")\n",
        "    plt.title(\"Length distribution\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"/content/len_hist.png\", dpi=200)\n",
        "    plt.close()\n",
        "    print(\"[saved] /content/len_hist.png\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "id": "gzsO4xp6F12c",
        "outputId": "fc641fad-6770-4fc7-8f37-d9e6f681823a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "not found: /content/baseline.trk",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-916059941.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mtrk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/baseline.trk\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"not found: {trk}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0msft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_trk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"same\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: not found: /content/baseline.trk"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Save streamlines correctly on DIPY 1.8 ---\n",
        "import numpy as np, nibabel as nib\n",
        "from dipy.io.stateful_tractogram import StatefulTractogram, Space\n",
        "from dipy.io.streamline import save_trk\n",
        "\n",
        "out_trk = \"/content/baseline.trk\"\n",
        "\n",
        "# 参照画像（空ボリューム）を作成\n",
        "ref_img = nib.Nifti1Image(np.zeros(data.shape[:3], dtype=np.float32), affine)\n",
        "\n",
        "# LocalTracking の出力は voxel 座標なので Space.VOX を指定\n",
        "sft = StatefulTractogram(streamlines, ref_img, Space.VOX)\n",
        "save_trk(sft, out_trk)\n",
        "\n",
        "print(\"[saved]\", out_trk)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 502
        },
        "id": "6uBev5lNGatw",
        "outputId": "eecc57de-dd97-4842-ec8f-ae29995fd32d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:StatefulTractogram:Voxel space values lower than 0.0.\n",
            "ERROR:StatefulTractogram:Voxel space values higher than dimensions.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Bounding box is not valid in voxel space, cannot load a valid file if some coordinates are invalid.\nPlease set bbox_valid_check to False and then use the function remove_invalid_streamlines to discard invalid streamlines.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1563672190.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# LocalTracking の出力は voxel 座標なので Space.VOX を指定\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0msft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStatefulTractogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstreamlines\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSpace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVOX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0msave_trk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_trk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[saved]\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_trk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/dipy/io/streamline.py\u001b[0m in \u001b[0;36mf_gen\u001b[0;34m(sft, filename, bbox_valid_check)\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"for more general cases, use save_tractogram instead.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m         \u001b[0msave_tractogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbbox_valid_check\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbbox_valid_check\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     f_gen.__doc__ = save_tractogram.__doc__.replace(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/dipy/io/streamline.py\u001b[0m in \u001b[0;36msave_tractogram\u001b[0;34m(sft, filename, bbox_valid_check)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbbox_valid_check\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_bbox_in_vox_valid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         raise ValueError('Bounding box is not valid in voxel space, cannot '\n\u001b[0m\u001b[1;32m     43\u001b[0m                          \u001b[0;34m'load a valid file if some coordinates are invalid.\\n'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                          \u001b[0;34m'Please set bbox_valid_check to False and then use '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Bounding box is not valid in voxel space, cannot load a valid file if some coordinates are invalid.\nPlease set bbox_valid_check to False and then use the function remove_invalid_streamlines to discard invalid streamlines."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- QC: load whichever exists and print stats ---\n",
        "import os, numpy as np, matplotlib.pyplot as plt\n",
        "from dipy.io.streamline import load_trk\n",
        "from dipy.io.stateful_tractogram import Space\n",
        "from dipy.tracking.streamline import length\n",
        "\n",
        "candidates = [\"/content/baseline.trk\", \"/content/B_streamlines.trk\"]\n",
        "trk = next((p for p in candidates if os.path.exists(p)), None)\n",
        "if trk is None:\n",
        "    raise FileNotFoundError(f\"not found: {candidates}\")\n",
        "\n",
        "sft = load_trk(trk, \"same\")\n",
        "sft.to_space(Space.RASMM)  # 長さを mm で評価\n",
        "sl = sft.streamlines\n",
        "lens = np.array([length(s) for s in sl]) if len(sl) else np.array([])\n",
        "\n",
        "print(f\"[OK] file: {trk}\")\n",
        "print(f\"streamlines: {len(sl)}\")\n",
        "if len(sl):\n",
        "    print(f\"length (mm): mean={lens.mean():.1f} ± {lens.std():.1f}  \"\n",
        "          f\"min/max={lens.min():.1f}/{lens.max():.1f}\")\n",
        "    plt.figure()\n",
        "    plt.hist(lens, bins=30)\n",
        "    plt.xlabel(\"Streamline length (mm)\"); plt.ylabel(\"Count\")\n",
        "    plt.title(\"Length distribution\"); plt.tight_layout()\n",
        "    plt.savefig(\"/content/len_hist.png\", dpi=200); plt.close()\n",
        "    print(\"[saved] /content/len_hist.png\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6hUZoZaNGsua",
        "outputId": "3b14d373-0156-4d20-9934-492dcf1c1a4d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OK] file: /content/B_streamlines.trk\n",
            "streamlines: 204419\n",
            "length (mm): mean=14.7 ± 25.0  min/max=0.0/253.5\n",
            "[saved] /content/len_hist.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Streamline length ヒストグラムをPDF出力 ===\n",
        "import os, numpy as np, matplotlib.pyplot as plt\n",
        "from dipy.io.streamline import load_trk\n",
        "from dipy.io.stateful_tractogram import Space\n",
        "from dipy.tracking.streamline import length\n",
        "\n",
        "# フォントをアウトライン化せずTrueType埋め込み（Illustrator等で編集しやすい）\n",
        "plt.rcParams[\"pdf.fonttype\"] = 42\n",
        "plt.rcParams[\"ps.fonttype\"]  = 42\n",
        "\n",
        "candidates = [\"/content/baseline.trk\", \"/content/B_streamlines.trk\"]\n",
        "trk = next((p for p in candidates if os.path.exists(p)), None)\n",
        "if trk is None:\n",
        "    raise FileNotFoundError(f\"not found: {candidates}\")\n",
        "\n",
        "sft = load_trk(trk, \"same\")\n",
        "sft.to_space(Space.RASMM)  # 長さをmmで評価\n",
        "sl   = sft.streamlines\n",
        "lens = np.array([length(s) for s in sl]) if len(sl) else np.array([])\n",
        "\n",
        "print(f\"[OK] file: {trk}\")\n",
        "print(f\"streamlines: {len(sl)}\")\n",
        "if len(sl):\n",
        "    print(f\"length (mm): mean={lens.mean():.1f} ± {lens.std():.1f}  \"\n",
        "          f\"min/max={lens.min():.1f}/{lens.max():.1f}\")\n",
        "\n",
        "    # 図を再描画 → PDF/PNG で保存\n",
        "    plt.figure(figsize=(6,4))\n",
        "    plt.hist(lens, bins=30)\n",
        "    plt.xlabel(\"Streamline length (mm)\")\n",
        "    plt.ylabel(\"Count\")\n",
        "    plt.title(\"Length distribution\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"/content/len_hist.pdf\")            # ベクター（推奨）\n",
        "    plt.savefig(\"/content/len_hist.png\", dpi=300)   # 参考に高解像度PNGも\n",
        "    plt.close()\n",
        "    print(\"[saved] /content/len_hist.pdf\")\n",
        "    print(\"[saved] /content/len_hist.png\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6rSM9Do_JlUA",
        "outputId": "4c42792c-88ca-412b-8d51-b4e78d898d98"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OK] file: /content/B_streamlines.trk\n",
            "streamlines: 204419\n",
            "length (mm): mean=14.7 ± 25.0  min/max=0.0/253.5\n",
            "[saved] /content/len_hist.pdf\n",
            "[saved] /content/len_hist.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === ECDF comparison of streamline lengths across methods (PDF) ===\n",
        "import os, numpy as np, matplotlib.pyplot as plt\n",
        "from dipy.io.streamline import load_trk\n",
        "from dipy.io.stateful_tractogram import Space\n",
        "from dipy.tracking.streamline import length\n",
        "from scipy.stats import ks_2samp\n",
        "\n",
        "plt.rcParams[\"pdf.fonttype\"] = 42\n",
        "plt.rcParams[\"ps.fonttype\"]  = 42\n",
        "\n",
        "# ここに比較したい .trk を列挙（存在するものだけ拾います）\n",
        "candidates = {\n",
        "    \"Baseline (CSD-det)\": \"/content/baseline.trk\",\n",
        "    \"Proposed (CGTAD)\":   \"/content/B_streamlines.trk\",\n",
        "    # \"SOTA: UKF\": \"/content/ukf.trk\",\n",
        "    # \"SOTA: Probtrackx\": \"/content/prob.trk\",\n",
        "}\n",
        "\n",
        "lengths = {}\n",
        "for name, path in candidates.items():\n",
        "    if not os.path.exists(path):\n",
        "        continue\n",
        "    sft = load_trk(path, \"same\", bbox_valid_check=False)\n",
        "    sft.to_space(Space.RASMM)\n",
        "    L = np.array([length(s) for s in sft.streamlines], dtype=float)\n",
        "    L = L[np.isfinite(L)]\n",
        "    lengths[name] = L\n",
        "\n",
        "# 要約表示 & KS検定（Baselineを基準に）\n",
        "keys = list(lengths.keys())\n",
        "if not keys:\n",
        "    raise FileNotFoundError(\"No .trk files found.\")\n",
        "base = keys[0]\n",
        "print(f\"[base] {base}  n={len(lengths[base])}\")\n",
        "\n",
        "for k in keys:\n",
        "    L = lengths[k]\n",
        "    if len(L)==0: continue\n",
        "    q5, q50, q95 = np.percentile(L, [5,50,95])\n",
        "    print(f\"[{k:>18}] n={len(L):5d}  mean={L.mean():6.1f}  sd={L.std():5.1f}  \"\n",
        "          f\"p5/p50/p95={q5:5.1f}/{q50:5.1f}/{q95:5.1f}\")\n",
        "    if k != base and len(lengths[base]) and len(L):\n",
        "        D, p = ks_2samp(lengths[base], L)\n",
        "        print(f\"  KS vs {base}: D={D:.3f}, p={p:.3e}\")\n",
        "\n",
        "# ECDF 図（PDF保存）\n",
        "plt.figure(figsize=(6,4))\n",
        "for k, L in lengths.items():\n",
        "    if len(L)==0: continue\n",
        "    x = np.sort(L)\n",
        "    y = np.arange(1, len(x)+1)/len(x)\n",
        "    plt.step(x, y, where=\"post\", label=k)\n",
        "plt.xlabel(\"Streamline length (mm)\")\n",
        "plt.ylabel(\"ECDF\")\n",
        "plt.xlim(left=0)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"/content/len_ecdf.pdf\")\n",
        "plt.close()\n",
        "print(\"[saved] /content/len_ecdf.pdf\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nHyK2fbrXg5K",
        "outputId": "1896fa34-6b8d-4f37-d98e-f496bd711bd6"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[base] Baseline (CSD-det)  n=14829\n",
            "[Baseline (CSD-det)] n=14829  mean=  94.8  sd= 89.4  p5/p50/p95=  3.0/ 69.0/276.0\n",
            "[  Proposed (CGTAD)] n=204419  mean=  14.7  sd= 25.0  p5/p50/p95=  2.0/  5.0/ 77.5\n",
            "  KS vs Baseline (CSD-det): D=0.612, p=0.000e+00\n",
            "[saved] /content/len_ecdf.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Bundle overlap / Dice coefficient ===\n",
        "import os, numpy as np, nibabel as nib\n",
        "from dipy.io.streamline import load_trk\n",
        "from dipy.io.stateful_tractogram import Space\n",
        "\n",
        "# ---- 入力（必要に応じて差し替え）----\n",
        "paths = {\n",
        "    \"Baseline\": \"/content/baseline.trk\",\n",
        "    \"Proposed\": \"/content/B_streamlines.trk\",\n",
        "    # \"SOTA-UKF\": \"/content/ukf.trk\",\n",
        "}\n",
        "roi_mask_path = None  # 例: \"/content/ROI_bundle.nii.gz\"  (ROIがあれば指定; 無ければ None)\n",
        "\n",
        "# ---- ユーティリティ ----\n",
        "def to_voxel_streamlines(trk_path):\n",
        "    sft = load_trk(trk_path, \"same\", bbox_valid_check=False)\n",
        "    sft.to_space(Space.VOX)\n",
        "    return sft.streamlines\n",
        "\n",
        "def infer_shape_from_streamlines(streamlines_list, margin=2):\n",
        "    pts = np.vstack([p for sl in streamlines_list for p in sl])  # すべての点を結合\n",
        "    mx = np.ceil(pts.max(axis=0) + margin).astype(int)\n",
        "    mx = np.maximum(mx, 1)\n",
        "    return tuple(mx.tolist())\n",
        "\n",
        "def visitation_mask(streamlines, vol_shape):\n",
        "    m = np.zeros(vol_shape, dtype=bool)\n",
        "    for sl in streamlines:\n",
        "        ijk = np.rint(sl).astype(int)\n",
        "        ijk = ijk[(ijk[:,0]>=0)&(ijk[:,1]>=0)&(ijk[:,2]>=0)]\n",
        "        ijk[:,0] = np.clip(ijk[:,0], 0, vol_shape[0]-1)\n",
        "        ijk[:,1] = np.clip(ijk[:,1], 0, vol_shape[1]-1)\n",
        "        ijk[:,2] = np.clip(ijk[:,2], 0, vol_shape[2]-1)\n",
        "        m[ijk[:,0], ijk[:,1], ijk[:,2]] = True\n",
        "    return m\n",
        "\n",
        "def dice_coef(A, B, eps=1e-8):\n",
        "    inter = np.logical_and(A, B).sum()\n",
        "    return 2.0 * inter / (A.sum() + B.sum() + eps)\n",
        "\n",
        "# ---- 読み込み＆体積マスク化 ----\n",
        "name2sl = {}\n",
        "for name, p in paths.items():\n",
        "    if os.path.exists(p):\n",
        "        name2sl[name] = to_voxel_streamlines(p)\n",
        "    else:\n",
        "        print(f\"[skip] not found: {p}\")\n",
        "        continue\n",
        "\n",
        "if not name2sl:\n",
        "    raise FileNotFoundError(\"No .trk found.\")\n",
        "\n",
        "# 体積サイズを決める（ROIがあればそれに合わせる）\n",
        "if roi_mask_path and os.path.exists(roi_mask_path):\n",
        "    roi_img = nib.load(roi_mask_path)\n",
        "    vol_shape = roi_img.shape[:3]\n",
        "    roi = roi_img.get_fdata() > 0\n",
        "else:\n",
        "    vol_shape = infer_shape_from_streamlines(list(name2sl.values()))\n",
        "    roi = None\n",
        "\n",
        "name2mask = {name: visitation_mask(sl, vol_shape) for name, sl in name2sl.items()}\n",
        "if roi is not None:\n",
        "    name2mask = {k: np.logical_and(v, roi) for k, v in name2mask.items()}\n",
        "\n",
        "# ---- Dice の一覧（1つ目を基準に）----\n",
        "names = list(name2mask.keys())\n",
        "base = names[0]\n",
        "print(f\"[base for Dice] {base}\")\n",
        "for n in names:\n",
        "    if n == base:\n",
        "        continue\n",
        "    d = dice_coef(name2mask[base], name2mask[n])\n",
        "    print(f\"Dice({base} vs {n}) = {d:.3f}\")\n",
        "\n",
        "# もしGTのバンドルマスク(roi_mask_path)が \"正解\" なら、そのDiceも出す：\n",
        "if roi is not None:\n",
        "    for n in names:\n",
        "        d_gt = dice_coef(name2mask[n], roi)\n",
        "        print(f\"Dice({n} vs ROI-GT) = {d_gt:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ayGLH-GZKoF",
        "outputId": "7162e5c9-dd69-4d5b-a3c9-535add643713"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[base for Dice] Baseline\n",
            "Dice(Baseline vs Proposed) = 0.310\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Crossing-angle error (voxel-wise, k=2 dominant undirected orientations) ===\n",
        "import os, numpy as np, nibabel as nib\n",
        "from dipy.io.streamline import load_trk\n",
        "from dipy.io.stateful_tractogram import Space\n",
        "\n",
        "# ---- 入力 ----\n",
        "# 比較したい手法（最低2つ）。最初を基準(Reference)にして pairwise 差も出せます。\n",
        "paths = {\n",
        "    \"Baseline\": \"/content/baseline.trk\",\n",
        "    \"Proposed\": \"/content/B_streamlines.trk\",\n",
        "    # \"SOTA-UKF\": \"/content/ukf.trk\",\n",
        "}\n",
        "\n",
        "roi_mask_path = None  # ROIを使うならパスを指定\n",
        "\n",
        "\n",
        "# 既知のGT交差角（度）を各ボクセルに持つnii.gz（なければ None）\n",
        "# 例：一定角(60°)でよければ scalar_gt_angle_deg に値を入れる\n",
        "gt_angle_map_path = None  # e.g., \"/content/gt_crossing_angle_deg.nii.gz\"\n",
        "scalar_gt_angle_deg = None  # e.g., 60.0\n",
        "\n",
        "# クロッシングボクセルの抽出条件\n",
        "min_dirs_per_voxel = 12   # そのボクセルに集まる方向ベクトルの最小数\n",
        "min_separation_deg = 15.0 # 2クラスタの角度がこの値以上なら「交差」とみなす\n",
        "\n",
        "# ---- 方向ベクトルを集計（voxel空間） ----\n",
        "def to_voxel_streamlines(trk_path):\n",
        "    sft = load_trk(trk_path, \"same\", bbox_valid_check=False)\n",
        "    sft.to_space(Space.VOX)\n",
        "    return sft.streamlines\n",
        "\n",
        "def unit(v):\n",
        "    n = np.linalg.norm(v)\n",
        "    return v / (n + 1e-12)\n",
        "\n",
        "def voxel_orientations(streamlines, vol_shape):\n",
        "    # 各ボクセルに、ストリームライン区間の方向ベクトル（符号同一視）を貯める\n",
        "    vox2vecs = {}\n",
        "    for sl in streamlines:\n",
        "        if len(sl) < 2:\n",
        "            continue\n",
        "        segs = sl[1:] - sl[:-1]              # 区間ベクトル\n",
        "        mids = (sl[1:] + sl[:-1]) * 0.5      # 中点（どのボクセルに属すか）\n",
        "        ijk = np.rint(mids).astype(int)\n",
        "        # 体積外を除外＆クリップ\n",
        "        valid = (ijk[:,0]>=0)&(ijk[:,1]>=0)&(ijk[:,2]>=0)& \\\n",
        "                (ijk[:,0]<vol_shape[0])&(ijk[:,1]<vol_shape[1])&(ijk[:,2]<vol_shape[2])\n",
        "        ijk, segs = ijk[valid], segs[valid]\n",
        "        for v, (i,j,k) in zip(segs, ijk):\n",
        "            v = unit(v)\n",
        "            # 向き同一視（-v を v に合わせる）\n",
        "            if v[0]<0:\n",
        "                v = -v\n",
        "            key = (i,j,k)\n",
        "            if key not in vox2vecs:\n",
        "                vox2vecs[key] = []\n",
        "            vox2vecs[key].append(v)\n",
        "    # numpy化\n",
        "    for k in list(vox2vecs.keys()):\n",
        "        vox2vecs[k] = np.asarray(vox2vecs[k], dtype=float)\n",
        "    return vox2vecs\n",
        "\n",
        "def two_undirected_means(vecs, iters=12):\n",
        "    # v ~ -v を同一視した 2-means\n",
        "    V = vecs.copy()\n",
        "    if len(V) < 2:\n",
        "        return None\n",
        "    # 初期値：1つ目は平均方向、2つ目は最遠方向\n",
        "    c1 = unit(V.mean(axis=0))\n",
        "    proj = np.abs(V @ c1)\n",
        "    c2 = unit(V[np.argmin(proj)])\n",
        "    for _ in range(iters):\n",
        "        A, B = [], []\n",
        "        for v in V:\n",
        "            d1 = 1 - np.abs(v @ c1)\n",
        "            d2 = 1 - np.abs(v @ c2)\n",
        "            if d1 <= d2:\n",
        "                A.append(v if v @ c1 >= 0 else -v)\n",
        "            else:\n",
        "                B.append(v if v @ c2 >= 0 else -v)\n",
        "        if len(A)==0 or len(B)==0:\n",
        "            return None\n",
        "        c1 = unit(np.mean(A, axis=0))\n",
        "        c2 = unit(np.mean(B, axis=0))\n",
        "    # 角度は 0–90° に正規化\n",
        "    ang = np.degrees(np.arccos(np.clip(np.dot(c1, c2), -1, 1)))\n",
        "    ang = ang if ang <= 90 else 180 - ang\n",
        "    return ang, c1, c2\n",
        "\n",
        "def infer_shape_union(paths):\n",
        "    # すべてのtrkの点域から最小包囲ボリュームを作る\n",
        "    from itertools import chain\n",
        "    all_pts = []\n",
        "    for p in paths:\n",
        "        sl = to_voxel_streamlines(p)\n",
        "        if len(sl):\n",
        "            all_pts.extend(chain.from_iterable(sl))\n",
        "    P = np.asarray(all_pts) if all_pts else np.zeros((1,3))\n",
        "    mx = np.ceil(P.max(axis=0) + 2).astype(int)\n",
        "    mx = np.maximum(mx, 1)\n",
        "    return tuple(mx.tolist())\n",
        "\n",
        "# ---- 準備 ----\n",
        "existing = {n:p for n,p in paths.items() if os.path.exists(p)}\n",
        "if len(existing) < 1:\n",
        "    raise FileNotFoundError(\"No .trk found.\")\n",
        "vol_shape = infer_shape_union(list(existing.values()))\n",
        "\n",
        "name2angles = {}   # 各手法の {voxel_key: angle_deg}\n",
        "name2counts = {}   # 各手法の {voxel_key: num_vectors}\n",
        "\n",
        "for name, p in existing.items():\n",
        "    sl = to_voxel_streamlines(p)\n",
        "    vox2vecs = voxel_orientations(sl, vol_shape)\n",
        "    angs = {}\n",
        "    cnts = {}\n",
        "    for key, V in vox2vecs.items():\n",
        "        if len(V) < min_dirs_per_voxel:\n",
        "            continue\n",
        "        res = two_undirected_means(V)\n",
        "        if res is None:\n",
        "            continue\n",
        "        angle_deg, _, _ = res\n",
        "        if angle_deg >= min_separation_deg:\n",
        "            angs[key] = angle_deg\n",
        "            cnts[key] = len(V)\n",
        "    name2angles[name] = angs\n",
        "    name2counts[name] = cnts\n",
        "    print(f\"[{name}] crossing voxels: {len(angs)}\")\n",
        "\n",
        "# ---- 誤差評価（GTあり or 参照法あり）----\n",
        "def summarize_errors(errs, label):\n",
        "    if len(errs)==0:\n",
        "        print(f\"{label}: no overlapping crossing voxels.\")\n",
        "        return\n",
        "    E = np.array(errs)\n",
        "    q = np.percentile(E, [5,50,95])\n",
        "    print(f\"{label}: n={len(E)}  mean={E.mean():.2f}  sd={E.std():.2f}  \"\n",
        "          f\"p5/p50/p95={q[0]:.2f}/{q[1]:.2f}/{q[2]:.2f}\")\n",
        "\n",
        "errors = {}\n",
        "\n",
        "# ケース1: GT角マップ\n",
        "if gt_angle_map_path and os.path.exists(gt_angle_map_path):\n",
        "    gt_img = nib.load(gt_angle_map_path); GT = gt_img.get_fdata()\n",
        "    for name, angs in name2angles.items():\n",
        "        err = []\n",
        "        for (i,j,k), a in angs.items():\n",
        "            if 0<=i<GT.shape[0] and 0<=j<GT.shape[1] and 0<=k<GT.shape[2]:\n",
        "                g = GT[i,j,k]\n",
        "                if np.isfinite(g) and g>0:\n",
        "                    err.append(abs(a - g))\n",
        "        errors[name] = err\n",
        "        summarize_errors(err, f\"[GT] {name}\")\n",
        "\n",
        "# ケース2: スカラーGT角\n",
        "elif scalar_gt_angle_deg is not None:\n",
        "    g = float(scalar_gt_angle_deg)\n",
        "    for name, angs in name2angles.items():\n",
        "        err = [abs(a - g) for a in angs.values()]\n",
        "        errors[name] = err\n",
        "        summarize_errors(err, f\"[GT={g:.1f}°] {name}\")\n",
        "\n",
        "# ケース3: 参照法（最初の手法を基準に pairwise 差）\n",
        "else:\n",
        "    names = list(name2angles.keys())\n",
        "    ref = names[0]\n",
        "    for name in names[1:]:\n",
        "        common = set(name2angles[ref].keys()) & set(name2angles[name].keys())\n",
        "        err = [abs(name2angles[name][k] - name2angles[ref][k]) for k in common]\n",
        "        errors[(ref, name)] = err\n",
        "        summarize_errors(err, f\"[pairwise] {ref} vs {name}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        },
        "id": "T7WM-VG2ZTk7",
        "outputId": "d5a3e89d-3ac5-4ab3-d4dc-593dbc295191"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4037640255.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mmin_dirs_per_voxel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtwo_undirected_means\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-4037640255.py\u001b[0m in \u001b[0;36mtwo_undirected_means\u001b[0;34m(vecs, iters)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mV\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0md1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mc1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0md2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mc2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0md1\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0md2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m                 \u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mc1\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BNWcP68fiZRg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Baseline (CSD-deterministic) tractography → /content/baseline.trk ===\n",
        "import numpy as np, nibabel as nib\n",
        "from dipy.reconst.csdeconv import ConstrainedSphericalDeconvModel, auto_response_ssst\n",
        "from dipy.direction import peaks_from_model\n",
        "from dipy.data import default_sphere\n",
        "from dipy.tracking.local_tracking import LocalTracking\n",
        "from dipy.tracking.stopping_criterion import BinaryStoppingCriterion\n",
        "from dipy.tracking.utils import seeds_from_mask\n",
        "from dipy.io.stateful_tractogram import StatefulTractogram, Space\n",
        "from dipy.io.streamline import save_trk\n",
        "\n",
        "# 1) response（FA=0.7で見つからない環境があるので 0.6 に）\n",
        "try:\n",
        "    response, ratio = auto_response_ssst(gtab, data, roi_radius=10, fa_thr=0.6)\n",
        "except Exception as e:\n",
        "    # フォールバック：DTIから中央値レスポンスを作る\n",
        "    from dipy.reconst.dti import TensorModel\n",
        "    ten = TensorModel(gtab).fit(data, mask=mask)\n",
        "    evals = np.clip(ten.evals, 1e-4, 3e-3)\n",
        "    S0 = float(np.median(data[mask].mean(axis=-1)))\n",
        "    evals_med = np.median(evals[mask], axis=0)\n",
        "    response = (evals_med, S0)\n",
        "\n",
        "# 2) CSD + peaks\n",
        "csd = ConstrainedSphericalDeconvModel(gtab, response, sh_order=8)\n",
        "peaks = peaks_from_model(\n",
        "    model=csd, data=data, sphere=default_sphere,\n",
        "    relative_peak_threshold=0.5, min_separation_angle=25,\n",
        "    mask=mask, npeaks=2, normalize_peaks=True\n",
        ")\n",
        "\n",
        "# 3) seeds / stopping\n",
        "stop  = BinaryStoppingCriterion(mask)\n",
        "seeds = seeds_from_mask(mask, density=1, affine=affine)  # mm座標でseed\n",
        "\n",
        "# 4) LocalTracking（mm座標で出力）\n",
        "streamlines = list(LocalTracking(\n",
        "    peaks, stop, seeds, affine=affine,\n",
        "    step_size=0.5, return_all=False\n",
        "))\n",
        "\n",
        "# 5) save（DIPY 1.8 正式手順）\n",
        "ref_img = nib.Nifti1Image(np.zeros(data.shape[:3], dtype=np.float32), affine)\n",
        "sft = StatefulTractogram(streamlines, ref_img, Space.RASMM)\n",
        "save_trk(sft, \"/content/baseline.trk\")\n",
        "print(\"[saved] /content/baseline.trk  | n_streamlines:\", len(streamlines))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KjfpGdygd0IL",
        "outputId": "fd176835-5b3c-498c-867d-bba57028603e"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[saved] /content/baseline.trk  | n_streamlines: 14829\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === quick QC for baseline.trk ===\n",
        "import os, numpy as np\n",
        "from dipy.io.streamline import load_trk\n",
        "from dipy.io.stateful_tractogram import Space\n",
        "from dipy.tracking.streamline import length\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "trk = \"/content/baseline.trk\"\n",
        "assert os.path.exists(trk), \"baseline.trk がありません\"\n",
        "\n",
        "sft = load_trk(trk, \"same\", bbox_valid_check=False)  # ← 重要\n",
        "sft.to_space(Space.RASMM)\n",
        "sl = sft.streamlines\n",
        "L  = np.array([length(s) for s in sl])\n",
        "print(f\"[OK] baseline streamlines: {len(sl)}  mean={L.mean():.1f} mm\")\n",
        "\n",
        "plt.figure()\n",
        "plt.hist(L, bins=30); plt.xlabel(\"length (mm)\"); plt.ylabel(\"count\")\n",
        "plt.tight_layout(); plt.savefig(\"/content/baseline_len_hist.pdf\"); plt.close()\n",
        "print(\"[saved] /content/baseline_len_hist.pdf\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AGJtnfjufCkY",
        "outputId": "86cf394d-7916-47f5-d22c-5974cf4be9f0"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OK] baseline streamlines: 14829  mean=94.8 mm\n",
            "[saved] /content/baseline_len_hist.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== One-shot SOTA eval (fixed & overwrite) =====\n",
        "import os, numpy as np, nibabel as nib, matplotlib.pyplot as plt\n",
        "from dipy.io.streamline import load_trk, save_trk\n",
        "from dipy.io.stateful_tractogram import StatefulTractogram, Space\n",
        "from dipy.tracking.streamline import length\n",
        "\n",
        "# ---------------- Config ----------------\n",
        "Lmin = 20.0   # mm  以下を除外\n",
        "tau  = 3      # TDIしきい: 1ボクセルあたりtau本以上を有効とみなす\n",
        "\n",
        "candidates = {\n",
        "    \"Baseline (CSD-det)\": \"/content/baseline.trk\",\n",
        "    \"Proposed (CGTAD)\"  : \"/content/B_streamlines.trk\",\n",
        "    # \"SOTA: UKF\"       : \"/content/ukf.trk\",\n",
        "    # \"SOTA: Prob\"      : \"/content/prob.trk\",\n",
        "}\n",
        "\n",
        "# ---------------- Utilities ----------------\n",
        "def get_ref_img():\n",
        "    \"\"\"参照画像は data/affine を最優先で使用。無ければ最初のtrkから近似。\"\"\"\n",
        "    try:\n",
        "        ref = nib.Nifti1Image(np.zeros(data.shape[:3], dtype=np.float32), affine)\n",
        "        return ref\n",
        "    except Exception:\n",
        "        # fallback: first existing .trk\n",
        "        for p in candidates.values():\n",
        "            if os.path.exists(p):\n",
        "                sft = load_trk(p, \"same\", bbox_valid_check=False)\n",
        "                # dimensions は (X, Y, Z) のvoxel shape相当\n",
        "                shape = tuple(map(int, sft.dimensions))\n",
        "                ref = nib.Nifti1Image(np.zeros(shape, dtype=np.float32), sft.affine)\n",
        "                return ref\n",
        "        raise RuntimeError(\"No reference available: set data/affine or provide at least one .trk\")\n",
        "\n",
        "ref_img = get_ref_img()\n",
        "Ainv    = np.linalg.inv(ref_img.affine)\n",
        "vol_shape = ref_img.shape[:3]\n",
        "\n",
        "def in_bounds_mm(sl_mm):\n",
        "    \"\"\"mm座標のストリームラインが参照体積内か\"\"\"\n",
        "    P = np.c_[sl_mm, np.ones(len(sl_mm))]\n",
        "    ijk = (P @ Ainv.T)[:, :3]\n",
        "    return (\n",
        "        (ijk[:,0] >= 0).all() and (ijk[:,0] < vol_shape[0]).all() and\n",
        "        (ijk[:,1] >= 0).all() and (ijk[:,1] < vol_shape[1]).all() and\n",
        "        (ijk[:,2] >= 0).all() and (ijk[:,2] < vol_shape[2]).all()\n",
        "    )\n",
        "\n",
        "def load_to_mm(path):\n",
        "    sft = load_trk(path, \"same\", bbox_valid_check=False)\n",
        "    sft.to_space(Space.RASMM)\n",
        "    return sft, list(sft.streamlines)\n",
        "\n",
        "def filter_save_Lmin(path, name):\n",
        "    \"\"\"L>=Lmin & in-bounds を適用して _LminXX.trk を上書き保存\"\"\"\n",
        "    sft, sl = load_to_mm(path)\n",
        "    L = np.array([length(s) for s in sl], dtype=float)\n",
        "    keep = [s for s, l in zip(sl, L) if np.isfinite(l) and l >= Lmin]\n",
        "    keep_in = [s for s in keep if in_bounds_mm(s)]\n",
        "    out_p = path.replace(\".trk\", f\"_Lmin{int(Lmin)}.trk\")\n",
        "    sft_out = StatefulTractogram(keep_in, ref_img, Space.RASMM)\n",
        "    save_trk(sft_out, out_p, bbox_valid_check=False)\n",
        "    L_keep = np.array([length(s) for s in keep_in], dtype=float)\n",
        "    print(f\"[saved] {name}: {out_p}  n={len(keep_in)}  \"\n",
        "          f\"mean={L_keep.mean():.1f}  p50={np.percentile(L_keep,50):.1f}\")\n",
        "    return out_p, L_keep\n",
        "\n",
        "def ecdf_pdf(name2L, out_pdf):\n",
        "    plt.rcParams[\"pdf.fonttype\"] = 42; plt.rcParams[\"ps.fonttype\"] = 42\n",
        "    plt.figure(figsize=(6,4))\n",
        "    for name, L in name2L.items():\n",
        "        if len(L)==0: continue\n",
        "        x = np.sort(L); y = np.arange(1, len(x)+1)/len(x)\n",
        "        plt.step(x, y, where=\"post\", label=f\"{name} (n={len(L)})\")\n",
        "    plt.xlabel(\"Streamline length (mm)\"); plt.ylabel(\"ECDF\"); plt.xlim(left=Lmin)\n",
        "    plt.legend(); plt.tight_layout(); plt.savefig(out_pdf); plt.close()\n",
        "    print(f\"[saved] {out_pdf}\")\n",
        "\n",
        "def visitation_mask(sl_vox, vol_shape):\n",
        "    m = np.zeros(vol_shape, dtype=bool)\n",
        "    for sl in sl_vox:\n",
        "        ijk = np.rint(sl).astype(int)\n",
        "        valid = (ijk[:,0]>=0)&(ijk[:,1]>=0)&(ijk[:,2]>=0)\n",
        "        ijk = ijk[valid]\n",
        "        if len(ijk)==0: continue\n",
        "        ijk[:,0] = np.clip(ijk[:,0], 0, vol_shape[0]-1)\n",
        "        ijk[:,1] = np.clip(ijk[:,1], 0, vol_shape[1]-1)\n",
        "        ijk[:,2] = np.clip(ijk[:,2], 0, vol_shape[2]-1)\n",
        "        m[ijk[:,0], ijk[:,1], ijk[:,2]] = True\n",
        "    return m\n",
        "\n",
        "def tdi_counts(sl_vox, vol_shape):\n",
        "    c = np.zeros(vol_shape, dtype=np.int32)\n",
        "    for sl in sl_vox:\n",
        "        ijk = np.rint(sl).astype(int)\n",
        "        valid = (ijk[:,0]>=0)&(ijk[:,1]>=0)&(ijk[:,2]>=0)\n",
        "        ijk = ijk[valid]\n",
        "        if len(ijk)==0: continue\n",
        "        ijk[:,0] = np.clip(ijk[:,0], 0, vol_shape[0]-1)\n",
        "        ijk[:,1] = np.clip(ijk[:,1], 0, vol_shape[1]-1)\n",
        "        ijk[:,2] = np.clip(ijk[:,2], 0, vol_shape[2]-1)\n",
        "        c[ijk[:,0], ijk[:,1], ijk[:,2]] += 1\n",
        "    return c\n",
        "\n",
        "def dice(A,B,eps=1e-8):\n",
        "    inter = np.logical_and(A,B).sum()\n",
        "    return 2*inter/(A.sum()+B.sum()+eps)\n",
        "\n",
        "# ---------------- Run: filter & save ----------------\n",
        "existing = {n:p for n,p in candidates.items() if os.path.exists(p)}\n",
        "if not existing:\n",
        "    raise FileNotFoundError(\"No .trk found in candidates.\")\n",
        "\n",
        "filtered_paths, name2L = {}, {}\n",
        "for name, path in existing.items():\n",
        "    out_p, L_keep = filter_save_Lmin(path, name)\n",
        "    filtered_paths[name] = out_p\n",
        "    name2L[name] = L_keep\n",
        "\n",
        "# ---------------- ECDF (PDF) ----------------\n",
        "ecdf_pdf(name2L, \"/content/len_ecdf_Lmin.pdf\")\n",
        "\n",
        "# ---------------- Dice / TDI-Dice ----------------\n",
        "# voxel空間へ\n",
        "name2sl_vox = {}\n",
        "for name, p in filtered_paths.items():\n",
        "    sft = load_trk(p, \"same\", bbox_valid_check=False)\n",
        "    sft.to_space(Space.VOX)\n",
        "    name2sl_vox[name] = list(sft.streamlines)\n",
        "\n",
        "# 体積shapeは参照画像のshapeを採用\n",
        "vol_shape = ref_img.shape[:3]\n",
        "name2mask = {n: visitation_mask(sl, vol_shape) for n, sl in name2sl_vox.items()}\n",
        "names = list(name2mask.keys())\n",
        "base  = names[0]\n",
        "for n in names[1:]:\n",
        "    print(f\"Dice(L≥{int(Lmin)}): {base} vs {n} = {dice(name2mask[base], name2mask[n]):.3f}\")\n",
        "\n",
        "name2tdi = {n: tdi_counts(sl, vol_shape) for n, sl in name2sl_vox.items()}\n",
        "for n in names[1:]:\n",
        "    A = name2tdi[base] >= tau\n",
        "    B = name2tdi[n]    >= tau\n",
        "    print(f\"TDI-Dice(τ={tau}, L≥{int(Lmin)}): {base} vs {n} = {dice(A,B):.3f}\")\n",
        "\n",
        "# ---------------- Optional: match N to Baseline ----------------\n",
        "if len(names) >= 2:\n",
        "    base_name = names[0]\n",
        "    for n in names[1:]:\n",
        "        # 現手法の本数\n",
        "        sft_b = load_trk(filtered_paths[base_name], \"same\", bbox_valid_check=False); sft_b.to_space(Space.RASMM)\n",
        "        sft_p = load_trk(filtered_paths[n],        \"same\", bbox_valid_check=False); sft_p.to_space(Space.RASMM)\n",
        "        nb, np_ = len(sft_b.streamlines), len(sft_p.streamlines)\n",
        "        if np_ > nb and nb > 0:\n",
        "            rng = np.random.RandomState(0)\n",
        "            idx = rng.choice(np_, size=nb, replace=False)\n",
        "            sl_sub = [sft_p.streamlines[i] for i in idx]\n",
        "            sft_sub = StatefulTractogram(sl_sub, ref_img, Space.RASMM)\n",
        "            out_p = filtered_paths[n].replace(\".trk\", \"_matchN.trk\")\n",
        "            save_trk(sft_sub, out_p, bbox_valid_check=False)\n",
        "            print(f\"[saved] {n} matched to {base_name}: {out_p}  n={nb}\")\n",
        "        else:\n",
        "            print(f\"[info] {n}: n={np_} ≤ {base_name}: n={nb}  (no downsampling)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxkpV_ccGBGL",
        "outputId": "05b086e9-66c7-4191-8519-cd821a36a7e4"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[saved] Baseline (CSD-det): /content/baseline_Lmin20.trk  n=11576  mean=119.0  p50=90.0\n",
            "[saved] Proposed (CGTAD): /content/B_streamlines_Lmin20.trk  n=36167  mean=59.0  p50=50.5\n",
            "[saved] /content/len_ecdf_Lmin.pdf\n",
            "Dice(L≥20): Baseline (CSD-det) vs Proposed (CGTAD) = 0.539\n",
            "TDI-Dice(τ=3, L≥20): Baseline (CSD-det) vs Proposed (CGTAD) = 0.553\n",
            "[saved] Proposed (CGTAD) matched to Baseline (CSD-det): /content/B_streamlines_Lmin20_matchN.trk  n=11576\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Re-eval with matched-N ---\n",
        "import os, numpy as np, matplotlib.pyplot as plt\n",
        "from dipy.io.streamline import load_trk\n",
        "from dipy.io.stateful_tractogram import Space\n",
        "from dipy.tracking.streamline import length\n",
        "\n",
        "base = \"/content/baseline_Lmin20.trk\"\n",
        "prop = \"/content/B_streamlines_Lmin20_matchN.trk\"\n",
        "\n",
        "def load_len_mm(p):\n",
        "    sft = load_trk(p, \"same\", bbox_valid_check=False); sft.to_space(Space.RASMM)\n",
        "    sl = sft.streamlines\n",
        "    L  = np.array([length(s) for s in sl], dtype=float)\n",
        "    return sl, L, sft\n",
        "\n",
        "sl_b, L_b, sft_b = load_len_mm(base)\n",
        "sl_p, L_p, sft_p = load_len_mm(prop)\n",
        "\n",
        "# ECDF（PDF）\n",
        "plt.rcParams[\"pdf.fonttype\"]=42; plt.rcParams[\"ps.fonttype\"]=42\n",
        "plt.figure(figsize=(6,4))\n",
        "for name, L in {\"Baseline\":L_b, \"Proposed (matchN)\":L_p}.items():\n",
        "    x=np.sort(L); y=np.arange(1,len(x)+1)/len(x); plt.step(x,y,where=\"post\",label=f\"{name} (n={len(L)})\")\n",
        "plt.xlabel(\"Streamline length (mm)\"); plt.ylabel(\"ECDF\"); plt.tight_layout()\n",
        "plt.savefig(\"/content/len_ecdf_Lmin_matchN.pdf\"); plt.close()\n",
        "print(\"[saved] /content/len_ecdf_Lmin_matchN.pdf\")\n",
        "\n",
        "# Dice（訪問マスク）\n",
        "import numpy as np\n",
        "def visitation_mask(sl, shape):\n",
        "    m=np.zeros(shape,dtype=bool)\n",
        "    for s in sl:\n",
        "        ijk=np.rint(s).astype(int)\n",
        "        ijk[:,0]=np.clip(ijk[:,0],0,shape[0]-1)\n",
        "        ijk[:,1]=np.clip(ijk[:,1],0,shape[1]-1)\n",
        "        ijk[:,2]=np.clip(ijk[:,2],0,shape[2]-1)\n",
        "        m[ijk[:,0],ijk[:,1],ijk[:,2]]=True\n",
        "    return m\n",
        "shape = sft_b.dimensions[::-1]  # (X,Y,Z)\n",
        "A = visitation_mask(sl_b, shape); B = visitation_mask(sl_p, shape)\n",
        "dice = lambda X,Y: 2*np.logical_and(X,Y).sum()/(X.sum()+Y.sum()+1e-8)\n",
        "print(f\"Dice (matchN, L≥20): {dice(A,B):.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FB6onfoomErt",
        "outputId": "e507c15e-d848-408d-9446-3f9f5bbe9e3c"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[saved] /content/len_ecdf_Lmin_matchN.pdf\n",
            "Dice (matchN, L≥20): 0.478\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === TDI–Dice sensitivity + summary table (PDF+TeX) ===\n",
        "import os, numpy as np, nibabel as nib, matplotlib.pyplot as plt\n",
        "from dipy.io.streamline import load_trk\n",
        "from dipy.io.stateful_tractogram import Space\n",
        "from dipy.tracking.streamline import length\n",
        "\n",
        "# ---------------- Config ----------------\n",
        "# 既に作った Lmin版（と matchN があれば）をここに列挙\n",
        "base_trk = \"/content/baseline_Lmin20.trk\"\n",
        "methods = {\n",
        "    \"Proposed (CGTAD)\":         \"/content/B_streamlines_Lmin20.trk\",\n",
        "    \"Proposed (matchN)\":        \"/content/B_streamlines_Lmin20_matchN.trk\",  # あれば自動採用\n",
        "    # \"SOTA: UKF\":              \"/content/ukf_Lmin20.trk\",\n",
        "    # \"SOTA: Probtrackx\":       \"/content/prob_Lmin20.trk\",\n",
        "}\n",
        "tau_list = [1, 3, 5, 10, 15, 20]     # 感度解析する TDI しきい値\n",
        "roi_mask_path = None                  # 例: \"/content/ROI_bundle.nii.gz\"（任意）\n",
        "\n",
        "out_pdf = \"/content/tdi_dice_sensitivity.pdf\"\n",
        "out_tex = \"/content/table_sota_tdi_dice.tex\"\n",
        "\n",
        "# ---------------- Helpers ----------------\n",
        "def load_vox(p):\n",
        "    sft = load_trk(p, \"same\", bbox_valid_check=False)\n",
        "    sft.to_space(Space.VOX)\n",
        "    return list(sft.streamlines), sft\n",
        "\n",
        "def load_mm(p):\n",
        "    sft = load_trk(p, \"same\", bbox_valid_check=False)\n",
        "    sft.to_space(Space.RASMM)\n",
        "    sl = list(sft.streamlines)\n",
        "    L  = np.array([length(s) for s in sl], dtype=float)\n",
        "    return sl, L, sft\n",
        "\n",
        "def tdi_counts(sl_vox, vol_shape):\n",
        "    c = np.zeros(vol_shape, dtype=np.int32)\n",
        "    for s in sl_vox:\n",
        "        ijk = np.rint(s).astype(int)\n",
        "        valid = (ijk[:,0]>=0)&(ijk[:,1]>=0)&(ijk[:,2]>=0)\n",
        "        ijk = ijk[valid]\n",
        "        if len(ijk)==0: continue\n",
        "        ijk[:,0] = np.clip(ijk[:,0], 0, vol_shape[0]-1)\n",
        "        ijk[:,1] = np.clip(ijk[:,1], 0, vol_shape[1]-1)\n",
        "        ijk[:,2] = np.clip(ijk[:,2], 0, vol_shape[2]-1)\n",
        "        c[ijk[:,0], ijk[:,1], ijk[:,2]] += 1\n",
        "    return c\n",
        "\n",
        "def dice(A,B,eps=1e-8):\n",
        "    inter = np.logical_and(A,B).sum()\n",
        "    return 2*inter/(A.sum()+B.sum()+eps)\n",
        "\n",
        "# ---------------- Load base + methods ----------------\n",
        "assert os.path.exists(base_trk), f\"not found: {base_trk}\"\n",
        "sl_b_vox, sft_b = load_vox(base_trk)\n",
        "sl_b_mm,  L_b,  _ = load_mm(base_trk)\n",
        "vol_shape = sft_b.dimensions[::-1]  # (X,Y,Z)\n",
        "print(f\"[base] n={len(sl_b_mm)}  mean={L_b.mean():.1f}  p50={np.percentile(L_b,50):.1f}\")\n",
        "\n",
        "# ROI（任意）\n",
        "roi = None\n",
        "if roi_mask_path and os.path.exists(roi_mask_path):\n",
        "    roi_img = nib.load(roi_mask_path)\n",
        "    if roi_img.shape[:3] == vol_shape:\n",
        "        roi = roi_img.get_fdata() > 0\n",
        "        print(f\"[ROI] applied: {roi_mask_path}\")\n",
        "    else:\n",
        "        print(f\"[warn] ROI shape {roi_img.shape[:3]} != vol {vol_shape} (ignored)\")\n",
        "\n",
        "name2L = {\"Baseline\": L_b}\n",
        "name2tdi = {}\n",
        "\n",
        "# Base TDI\n",
        "tdi_base = tdi_counts(sl_b_vox, vol_shape)\n",
        "if roi is not None: tdi_base = tdi_base * roi\n",
        "name2tdi[\"Baseline\"] = tdi_base\n",
        "\n",
        "# Methods\n",
        "existing = {n:p for n,p in methods.items() if os.path.exists(p)}\n",
        "for name, p in existing.items():\n",
        "    sl_vox, _ = load_vox(p)\n",
        "    sl_mm,  L, _  = load_mm(p)\n",
        "    name2L[name]  = L\n",
        "    T = tdi_counts(sl_vox, vol_shape)\n",
        "    if roi is not None: T = T * roi\n",
        "    name2tdi[name] = T\n",
        "    print(f\"[{name}] n={len(L)}  mean={L.mean():.1f}  p50={np.percentile(L,50):.1f}\")\n",
        "\n",
        "# ---------------- TDI-Dice sensitivity curves ----------------\n",
        "plt.rcParams[\"pdf.fonttype\"] = 42; plt.rcParams[\"ps.fonttype\"] = 42\n",
        "plt.figure(figsize=(6,4))\n",
        "curves = {}  # for table\n",
        "\n",
        "for name, T in name2tdi.items():\n",
        "    if name == \"Baseline\":\n",
        "        continue\n",
        "    y = []\n",
        "    for tau in tau_list:\n",
        "        A = (name2tdi[\"Baseline\"] >= tau)\n",
        "        B = (T >= tau)\n",
        "        y.append(dice(A,B))\n",
        "    curves[name] = y\n",
        "    plt.plot(tau_list, y, marker=\"o\", label=name)\n",
        "\n",
        "plt.xlabel(r\"TDI threshold $\\tau$  (counts per voxel)\")\n",
        "plt.ylabel(\"Dice vs Baseline\")\n",
        "plt.xticks(tau_list)\n",
        "plt.ylim(0,1)\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.savefig(out_pdf); plt.close()\n",
        "print(f\"[saved] {out_pdf}\")\n",
        "\n",
        "# ---------------- Build LaTeX table ----------------\n",
        "# columns: n, mean(mm), p50(mm), Dice@tau=1,3,5,10,15,20（存在するtauのみ）\n",
        "def fmt(x):\n",
        "    return \"-\" if x is None else (f\"{x:.3f}\" if isinstance(x,float) else str(x))\n",
        "\n",
        "rows = []\n",
        "# Baseline row（Dice列は空欄）\n",
        "rows.append([\n",
        "    \"Baseline\",\n",
        "    len(name2L[\"Baseline\"]),\n",
        "    float(np.mean(name2L[\"Baseline\"])),\n",
        "    float(np.percentile(name2L[\"Baseline\"], 50)),\n",
        "] + [\"-\"]*len(tau_list))\n",
        "\n",
        "# Each method\n",
        "for name in existing.keys():\n",
        "    L = name2L[name]\n",
        "    stats = [len(L), float(np.mean(L)), float(np.percentile(L,50))]\n",
        "    dlist = [float(v) for v in curves[name]]\n",
        "    rows.append([name] + stats + dlist)\n",
        "\n",
        "# render TeX\n",
        "tex_lines = []\n",
        "tex_lines.append(r\"\\begin{table}[t]\")\n",
        "tex_lines.append(r\"\\centering\")\n",
        "cap = r\"TDI--Dice sensitivity vs.\\ Baseline after length filtering. Dice values are computed on TDI-thresholded visitation maps (voxel counts $\\ge \\tau$).\"\n",
        "tex_lines.append(r\"\\caption{\" + cap + r\"}\")\n",
        "tex_lines.append(r\"\\label{tab:tdi_dice_sensitivity}\")\n",
        "cols = \"l\" + \"r\"*3 + \"r\"*len(tau_list)\n",
        "tex_lines.append(r\"\\begin{tabular}{\" + cols + r\"}\")\n",
        "tex_lines.append(r\"\\toprule\")\n",
        "head1 = r\"Method & $n$ & mean [mm] & $p_{50}$ [mm]\"\n",
        "head2 = \" & \" + \" & \".join([fr\"Dice@$\\tau={t}$\" for t in tau_list])\n",
        "tex_lines.append(head1 + head2 + r\" \\\\\")\n",
        "tex_lines.append(r\"\\midrule\")\n",
        "for r in rows:\n",
        "    line = r\"{} & {} & {:.1f} & {:.1f}\".format(r[0], r[1], r[2], r[3])\n",
        "    for k in range(len(tau_list)):\n",
        "        v = r[4+k]\n",
        "        line += \" & \" + (fmt(v) if isinstance(v,str) else f\"{v:.3f}\")\n",
        "    tex_lines.append(line + r\" \\\\\")\n",
        "tex_lines.append(r\"\\bottomrule\")\n",
        "tex_lines.append(r\"\\end{tabular}\")\n",
        "tex_lines.append(r\"\\end{table}\")\n",
        "\n",
        "with open(out_tex, \"w\") as f:\n",
        "    f.write(\"\\n\".join(tex_lines))\n",
        "print(f\"[saved] {out_tex}\")\n",
        "\n",
        "# Also print path summary for convenience\n",
        "print(\"\\n[Artifacts]\")\n",
        "print(\" -\", out_pdf)\n",
        "print(\" -\", out_tex)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XbZnyEHCnjUU",
        "outputId": "8c85d541-867e-457b-b03d-99ef6a31a3eb"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[base] n=11576  mean=119.0  p50=90.0\n",
            "[Proposed (CGTAD)] n=36167  mean=59.0  p50=50.5\n",
            "[Proposed (matchN)] n=11576  mean=58.9  p50=50.5\n",
            "[saved] /content/tdi_dice_sensitivity.pdf\n",
            "[saved] /content/table_sota_tdi_dice.tex\n",
            "\n",
            "[Artifacts]\n",
            " - /content/tdi_dice_sensitivity.pdf\n",
            " - /content/table_sota_tdi_dice.tex\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Generate SOTA candidate: CSD-Prob (DIPY) → /content/csd_prob.trk ===\n",
        "import numpy as np, nibabel as nib\n",
        "from dipy.reconst.csdeconv import ConstrainedSphericalDeconvModel, auto_response_ssst\n",
        "from dipy.direction import ProbabilisticDirectionGetter\n",
        "from dipy.data import default_sphere\n",
        "from dipy.tracking.local_tracking import LocalTracking\n",
        "from dipy.tracking.stopping_criterion import BinaryStoppingCriterion\n",
        "from dipy.tracking.utils import seeds_from_mask\n",
        "from dipy.io.stateful_tractogram import StatefulTractogram, Space\n",
        "from dipy.io.streamline import save_trk\n",
        "\n",
        "# 1) response（FAしきいは安全側）\n",
        "try:\n",
        "    response, _ = auto_response_ssst(gtab, data, roi_radius=10, fa_thr=0.6)\n",
        "except Exception:\n",
        "    # Fallback: DTI中央値レスポンス\n",
        "    from dipy.reconst.dti import TensorModel\n",
        "    ten = TensorModel(gtab).fit(data, mask=mask)\n",
        "    evals = np.clip(ten.evals, 1e-4, 3e-3)\n",
        "    S0 = float(np.median(data[mask].mean(axis=-1)))\n",
        "    response = (np.median(evals[mask], axis=0), S0)\n",
        "\n",
        "# 2) CSD fit\n",
        "csd = ConstrainedSphericalDeconvModel(gtab, response, sh_order=8)\n",
        "csd_fit = csd.fit(data, mask=mask)\n",
        "\n",
        "# 3) Probabilistic direction getter（max_angleは30°前後が一般的）\n",
        "pdg = ProbabilisticDirectionGetter.from_shcoeff(\n",
        "    csd_fit.shm_coeff, max_angle=30., sphere=default_sphere\n",
        ")\n",
        "\n",
        "# 4) seeds / stopping\n",
        "stop  = BinaryStoppingCriterion(mask)\n",
        "seeds = seeds_from_mask(mask, density=1, affine=affine)\n",
        "\n",
        "# 5) tracking（mm座標で出力）\n",
        "streamlines = list(LocalTracking(pdg, stop, seeds, affine=affine, step_size=0.5, return_all=False))\n",
        "\n",
        "# 6) save\n",
        "ref_img = nib.Nifti1Image(np.zeros(data.shape[:3], dtype=np.float32), affine)\n",
        "sft = StatefulTractogram(streamlines, ref_img, Space.RASMM)\n",
        "save_trk(sft, \"/content/csd_prob.trk\", bbox_valid_check=False)\n",
        "print(\"[saved] /content/csd_prob.trk  n=\", len(streamlines))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQWHMk8pvUuj",
        "outputId": "f9676151-8f4b-4309-eebc-2c0d0d1d7829"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 184907/184907 [01:17<00:00, 2380.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[saved] /content/csd_prob.trk  n= 58208\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Convert external SOTA outputs to .trk (unified) ===\n",
        "import os, numpy as np, nibabel as nib, pathlib\n",
        "from dipy.io.stateful_tractogram import StatefulTractogram, Space\n",
        "from dipy.io.streamline import save_trk\n",
        "\n",
        "ref_img = nib.Nifti1Image(np.zeros(data.shape[:3], dtype=np.float32), affine)\n",
        "\n",
        "def convert_to_trk(in_path, out_path=None):\n",
        "    p = pathlib.Path(in_path)\n",
        "    ext = p.suffix.lower()\n",
        "    if out_path is None:\n",
        "        out_path = str(p.with_suffix(\".trk\"))\n",
        "    sl = None\n",
        "\n",
        "    if ext == \".trk\":\n",
        "        print(f\"[skip] already .trk: {p}\")\n",
        "        return str(p)\n",
        "\n",
        "    elif ext == \".tck\":\n",
        "        # MRtrix iFOD2 等\n",
        "        from nibabel.streamlines import load as load_sl\n",
        "        tck = load_sl(str(p))\n",
        "        sl = [np.asarray(s, dtype=np.float32) for s in tck.streamlines]  # MRtrixはRASMM\n",
        "        sft = StatefulTractogram(sl, ref_img, Space.RASMM)\n",
        "        save_trk(sft, out_path, bbox_valid_check=False)\n",
        "        print(f\"[conv] TCK→TRK: {p.name} → {out_path}  n={len(sl)}\")\n",
        "        return out_path\n",
        "\n",
        "    elif ext in [\".vtk\", \".vtp\"]:\n",
        "        # UKFTractography (VTK PolyData)\n",
        "        try:\n",
        "            import pyvista as pv\n",
        "        except Exception as e:\n",
        "            raise RuntimeError(\"pyvista が必要です。`pip install pyvista` を実行してください。\") from e\n",
        "        mesh = pv.read(str(p))\n",
        "        # PolyLines をstreamlines(list of Nx3)へ\n",
        "        sl = []\n",
        "        for cell in mesh.lines.reshape((-1, 3)) if mesh.lines.size % 3 == 0 else []:\n",
        "            pass  # 古いフォーマット回避のため別経路で読む\n",
        "        # より堅牢な抽出\n",
        "        for ids in mesh.extract_all_edges().lines.reshape(-1, 3) if False else []:\n",
        "            pass\n",
        "        # 汎用：pyvistaの `mesh.lines` は [npts, id0, id1, ..., npts, ...] 形式の場合あり\n",
        "        arr = mesh.lines.reshape((-1,))  # 1D\n",
        "        i = 0\n",
        "        while i < len(arr):\n",
        "            n = int(arr[i]); i += 1\n",
        "            idx = arr[i:i+n]; i += n\n",
        "            pts = np.asarray(mesh.points[idx], dtype=np.float32)\n",
        "            sl.append(pts)\n",
        "\n",
        "        if not sl:  # fallback: poly_data.lines_dict (pyvista>=0.43)\n",
        "            try:\n",
        "                for _, idx in mesh.lines_dict.items():\n",
        "                    pts = np.asarray(mesh.points[idx], dtype=np.float32)\n",
        "                    sl.append(pts)\n",
        "            except Exception:\n",
        "                pass\n",
        "\n",
        "        if not sl:\n",
        "            raise RuntimeError(f\"VTK 読み出しに失敗: {p}\")\n",
        "\n",
        "        sft = StatefulTractogram(sl, ref_img, Space.RASMM)  # UKF はRASMM\n",
        "        save_trk(sft, out_path, bbox_valid_check=False)\n",
        "        print(f\"[conv] VTK→TRK: {p.name} → {out_path}  n={len(sl)}\")\n",
        "        return out_path\n",
        "\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported extension: {ext}\")\n",
        "\n",
        "# 例：ここに外部SOTAのパス（存在するものだけでOK）\n",
        "external_inputs = {\n",
        "    \"SOTA: iFOD2\": \"/content/ifod2.tck\",          # MRtrix tck の想定出力\n",
        "    \"SOTA: UKF\":   \"/content/ukf.vtk\",            # UKFTractography の想定出力\n",
        "    \"FSL Probtrackx\": \"/content/probtrackx.tck\",  # tck化されているなら可\n",
        "}\n",
        "\n",
        "converted = {}\n",
        "for name, path in external_inputs.items():\n",
        "    if os.path.exists(path):\n",
        "        try:\n",
        "            out_trk = convert_to_trk(path)\n",
        "            converted[name] = out_trk\n",
        "        except Exception as e:\n",
        "            print(f\"[warn] convert failed for {name}: {e}\")\n",
        "    else:\n",
        "        print(f\"[skip] not found: {path}\")\n",
        "\n",
        "print(\"[converted]\", converted)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrD6Pusl0IDc",
        "outputId": "b56a934b-6cea-4e78-e9bd-5e8169ae97f7"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[skip] not found: /content/ifod2.tck\n",
            "[skip] not found: /content/ukf.vtk\n",
            "[skip] not found: /content/probtrackx.tck\n",
            "[converted] {}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Re-run sensitivity & table including SOTA methods ===\n",
        "import os, numpy as np, nibabel as nib, matplotlib.pyplot as plt\n",
        "from dipy.io.streamline import load_trk\n",
        "from dipy.io.stateful_tractogram import Space\n",
        "from dipy.tracking.streamline import length\n",
        "\n",
        "# ---- 設定 ----\n",
        "base_trk = \"/content/baseline_Lmin20.trk\"\n",
        "methods = {\n",
        "    \"Proposed (CGTAD)\"  : \"/content/B_streamlines_Lmin20.trk\",\n",
        "    \"Proposed (matchN)\" : \"/content/B_streamlines_Lmin20_matchN.trk\",\n",
        "    \"CSD-Prob (DIPY)\"   : \"/content/csd_prob.trk\",           # セルAの生成物\n",
        "    # ↓ セルBで変換できたら自動で拾います\n",
        "    \"SOTA: iFOD2\"       : \"/content/ifod2.trk\",\n",
        "    \"SOTA: UKF\"         : \"/content/ukf.trk\",\n",
        "    \"FSL Probtrackx\"    : \"/content/probtrackx.trk\",\n",
        "}\n",
        "tau_list = [1, 3, 5, 10, 15, 20]\n",
        "out_pdf = \"/content/tdi_dice_sensitivity_all.pdf\"\n",
        "out_tex = \"/content/table_sota_tdi_dice_all.tex\"\n",
        "\n",
        "def load_mm(p):\n",
        "    sft = load_trk(p, \"same\", bbox_valid_check=False)\n",
        "    sft.to_space(Space.RASMM)\n",
        "    sl = list(sft.streamlines)\n",
        "    L  = np.array([length(s) for s in sl], dtype=float)\n",
        "    return sl, L, sft\n",
        "\n",
        "def load_vox(p):\n",
        "    sft = load_trk(p, \"same\", bbox_valid_check=False)\n",
        "    sft.to_space(Space.VOX)\n",
        "    return list(sft.streamlines), sft\n",
        "\n",
        "def tdi_counts(sl_vox, shape):\n",
        "    c = np.zeros(shape, dtype=np.int32)\n",
        "    for s in sl_vox:\n",
        "        ijk = np.rint(s).astype(int)\n",
        "        valid = (ijk[:,0]>=0)&(ijk[:,1]>=0)&(ijk[:,2]>=0)\n",
        "        ijk = ijk[valid]\n",
        "        if len(ijk)==0: continue\n",
        "        ijk[:,0] = np.clip(ijk[:,0], 0, shape[0]-1)\n",
        "        ijk[:,1] = np.clip(ijk[:,1], 0, shape[1]-1)\n",
        "        ijk[:,2] = np.clip(ijk[:,2], 0, shape[2]-1)\n",
        "        c[ijk[:,0], ijk[:,1], ijk[:,2]] += 1\n",
        "    return c\n",
        "\n",
        "dice = lambda A,B: 2*np.logical_and(A,B).sum()/(A.sum()+B.sum()+1e-8)\n",
        "\n",
        "# ---- Base ----\n",
        "assert os.path.exists(base_trk), f\"not found: {base_trk}\"\n",
        "sl_b_vox, sft_b = load_vox(base_trk)\n",
        "sl_b_mm,  L_b,  _ = load_mm(base_trk)\n",
        "shape = sft_b.dimensions[::-1]\n",
        "T_base = tdi_counts(sl_b_vox, shape)\n",
        "\n",
        "name2L = {\"Baseline\": L_b}\n",
        "curves = {}\n",
        "\n",
        "# ---- Each method ----\n",
        "plt.rcParams[\"pdf.fonttype\"]=42; plt.rcParams[\"ps.fonttype\"]=42\n",
        "plt.figure(figsize=(6,4))\n",
        "for name, p in methods.items():\n",
        "    if not os.path.exists(p):\n",
        "        print(f\"[skip] {name}: {p}\")\n",
        "        continue\n",
        "    sl_v, _ = load_vox(p)\n",
        "    _, L, _ = load_mm(p)\n",
        "    name2L[name] = L\n",
        "    T = tdi_counts(sl_v, shape)\n",
        "    y = []\n",
        "    for tau in tau_list:\n",
        "        y.append(dice(T_base>=tau, T>=tau))\n",
        "    curves[name] = y\n",
        "    plt.plot(tau_list, y, marker=\"o\", label=name)\n",
        "plt.xlabel(r\"TDI threshold $\\tau$  (counts/voxel)\")\n",
        "plt.ylabel(\"Dice vs Baseline\"); plt.xticks(tau_list); plt.ylim(0,1); plt.grid(True,alpha=.3)\n",
        "plt.legend(fontsize=8); plt.tight_layout(); plt.savefig(out_pdf); plt.close()\n",
        "print(\"[saved]\", out_pdf)\n",
        "\n",
        "# ---- LaTeX table ----\n",
        "rows = []\n",
        "rows.append([\"Baseline\", len(name2L[\"Baseline\"]), float(np.mean(name2L[\"Baseline\"])), float(np.percentile(name2L[\"Baseline\"],50))] + [\"-\"]*len(tau_list))\n",
        "for name in methods:\n",
        "    if name not in name2L: continue\n",
        "    L = name2L[name]\n",
        "    stats = [len(L), float(np.mean(L)), float(np.percentile(L,50))]\n",
        "    dlist = [float(v) for v in curves[name]]\n",
        "    rows.append([name] + stats + dlist)\n",
        "\n",
        "def fmt_row(r):\n",
        "    line = r\"{} & {} & {:.1f} & {:.1f}\".format(r[0], r[1], r[2], r[3])\n",
        "    for v in r[4:]:\n",
        "        line += \" & \" + (f\"{v:.3f}\" if isinstance(v,float) else v)\n",
        "    return line + r\" \\\\\"\n",
        "\n",
        "tex = []\n",
        "tex += [r\"\\begin{table*}[t]\", r\"\\centering\"]\n",
        "tex += [r\"\\caption{TDI--Dice sensitivity vs.\\ Baseline after length filtering (all methods).}\"]\n",
        "tex += [r\"\\label{tab:tdi_dice_sensitivity_all}\"]\n",
        "tex += [r\"\\setlength{\\tabcolsep}{3pt}\\renewcommand{\\arraystretch}{1.05}\"]\n",
        "tex += [r\"\\resizebox{\\textwidth}{!}{%\"]\n",
        "tex += [r\"\\begin{tabular}{lrrrr\" + \"r\"*len(tau_list) + r\"}\", r\"\\toprule\"]\n",
        "tex += [r\"Method & $n$ & mean [mm] & $p_{50}$ [mm] & \\multicolumn{\" + str(len(tau_list)) + r\"}{c}{Dice vs.\\ Baseline at $\\tau$} \\\\\", r\"\\cmidrule(l){5-\" + str(4+len(tau_list)) + r\"}\"]\n",
        "tex += [r\" &  &  &  & \" + \" & \".join([str(t) for t in tau_list]) + r\" \\\\\", r\"\\midrule\"]\n",
        "for r in rows: tex += [fmt_row(r)]\n",
        "tex += [r\"\\bottomrule\", r\"\\end{tabular}%\", r\"}\", r\"\\end{table*}\"]\n",
        "\n",
        "with open(out_tex, \"w\") as f:\n",
        "    f.write(\"\\n\".join(tex))\n",
        "print(\"[saved]\", out_tex)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fXRRy70O0Pa2",
        "outputId": "673267e1-62aa-4a44-df8a-7d08d700b4fd"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[skip] SOTA: iFOD2: /content/ifod2.trk\n",
            "[skip] SOTA: UKF: /content/ukf.trk\n",
            "[skip] FSL Probtrackx: /content/probtrackx.trk\n",
            "[saved] /content/tdi_dice_sensitivity_all.pdf\n",
            "[saved] /content/table_sota_tdi_dice_all.tex\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EdUS5I6G4jdT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}